{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDegZLOcHnrMXEnW1EQBKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunSik312/623_chungnam/blob/main/7%EC%9B%9416%EC%9D%BCImageNet%EC%BD%94%EB%93%9C%EB%B6%84%EC%84%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "í˜„ì¬ ì½”ë“œì— ì‚¬ìš©ëœ í•¨ìˆ˜ê°€ ê° ì–´ë–¤ ê¸°ëŠ¥ì„ í•˜ëŠ”ì§€ ê³µë¶€í•˜ê¸°\n",
        "torch: ë”¥ëŸ¬ë‹ í•µì‹¬ ì—”ì§„ (í…ì„œ, GPU, ìë™ë¯¸ë¶„)\n",
        "\n",
        "torch.nn: ì‹ ê²½ë§ êµ¬ì¶• ë„êµ¬ (ë ˆì´ì–´, ì†ì‹¤í•¨ìˆ˜, ëª¨ë¸)\n",
        "\n",
        "torchvision: ì»´í“¨í„° ë¹„ì „ ì „ìš© (ëª¨ë¸, ë³€í™˜, ë°ì´í„°ì…‹)\n",
        "\n",
        "requests: HTTP í†µì‹  (íŒŒì¼ ë‹¤ìš´ë¡œë“œ, API í˜¸ì¶œ)\n",
        "\n",
        "json: ë°ì´í„° êµí™˜ (ì„¤ì • íŒŒì¼, ì–´ë…¸í…Œì´ì…˜)"
      ],
      "metadata": {
        "id": "MYPQp483ow1L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pSsZwQdn0PS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import json\n",
        "from io import BytesIO\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#torch.nn:\n",
        "\n",
        "torchì˜ êµ¬ì„±ìš”ì†Œ\n",
        "\n",
        "ì£¼ìš” êµ¬ì„± ìš”ì†Œ\n",
        "ë ˆì´ì–´ (torch.nn):\n",
        "\n",
        "Linear - ì™„ì „ì—°ê²°ì¸µ (Fully Connected Layer)\n",
        "\n",
        "Conv1d, Conv2d, Conv3d - í•©ì„±ê³±ì¸µ\n",
        "\n",
        "LSTM, GRU, RNN - ìˆœí™˜ì‹ ê²½ë§ì¸µ\n",
        "\n",
        "BatchNorm1d, BatchNorm2d - ë°°ì¹˜ ì •ê·œí™”\n",
        "\n",
        "Dropout - ë“œë¡­ì•„ì›ƒ (ì •ê·œí™” ê¸°ë²•)\n",
        "\n",
        "Embedding - ì„ë² ë”©ì¸µ (ë²”ì£¼í˜• ë°ì´í„° ì²˜ë¦¬)\n",
        "\n",
        "\n",
        "í™œì„±í™” í•¨ìˆ˜:\n",
        "\n",
        "ReLU, Sigmoid, Tanh, LeakyReLU, GELU\n",
        "\n",
        "Softmax, LogSoftmax\n",
        "\n",
        "ì†ì‹¤ í•¨ìˆ˜:\n",
        "\n",
        "CrossEntropyLoss - êµì°¨ì—”íŠ¸ë¡œí”¼ ì†ì‹¤\n",
        "\n",
        "MSELoss - í‰ê· ì œê³±ì˜¤ì°¨\n",
        "\n",
        "BCELoss - ì´ì§„ êµì°¨ì—”íŠ¸ë¡œí”¼\n",
        "\n",
        "NLLLoss, L1Loss, SmoothL1Loss\n",
        "\n",
        "ì»¨í…Œì´ë„ˆ:\n",
        "\n",
        "Sequential - ë ˆì´ì–´ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°\n",
        "\n",
        "ModuleList - ëª¨ë“ˆë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
        "\n",
        "ModuleDict - ëª¨ë“ˆë“¤ì˜ ë”•ì…”ë„ˆë¦¬"
      ],
      "metadata": {
        "id": "nELTy2c7sURL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#torchvision\n",
        "\n",
        "torchvision.datasets\n",
        "ë¯¸ë¦¬ ì¤€ë¹„ëœ ë°ì´í„°ì…‹ë“¤ì„ ì‰½ê²Œ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "torchvision.transforms\n",
        "ì´ë¯¸ì§€ ì „ì²˜ë¦¬ì™€ ë°ì´í„° ì¦ê°•ì„ ìœ„í•œ ë³€í™˜ í•¨ìˆ˜ë“¤ì…ë‹ˆë‹¤.\n",
        "\n",
        "torchvision.models\n",
        "ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "torchvision.utils\n",
        "ì‹œê°í™”ì™€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì…ë‹ˆë‹¤.\n",
        "\n",
        "ì£¼ìš” ì¥ì :\n",
        "\n",
        "í‘œì¤€ ë°ì´í„°ì…‹ì— ì‰½ê²Œ ì ‘ê·¼ ê°€ëŠ¥\n",
        "\n",
        "ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë„êµ¬ ì œê³µ\n",
        "\n",
        "ê²€ì¦ëœ ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ë“¤ í™œìš© ê°€ëŠ¥\n",
        "\n",
        "ì»´í“¨í„° ë¹„ì „ ì‘ì—…ì„ ìœ„í•œ í†µí•©ëœ í™˜ê²½"
      ],
      "metadata": {
        "id": "DHrxmWvqsYab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#requests\n",
        "Pythonì—ì„œ HTTP ìš”ì²­ì„ ì‰½ê²Œ ë³´ë‚¼ ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "ì‚¬ìš©ë²•\n",
        "1. GET ìš”ì²­\n",
        "2. POST ìš”ì²­\n",
        "3. ê¸°íƒ€ HTTP ë©”ì„œë“œ"
      ],
      "metadata": {
        "id": "ptXgQqw7sguU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#json\n",
        " Pythonì˜ ë‚´ì¥ ëª¨ë“ˆë¡œ, JSON(JavaScript Object Notation) ë°ì´í„° í˜•ì‹ì„ ë‹¤ë£¨ê¸° ìœ„í•œ ê¸°ëŠ¥ì„ ì œê³µ"
      ],
      "metadata": {
        "id": "FMrRK3K1s3mF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ImageNet 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ê¸°\n",
        "# ============================================================================="
      ],
      "metadata": {
        "id": "uf_Vn8jGoryK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ!\")\n",
        "print(f\"ğŸ”¥ PyTorch ë²„ì „: {torch.__version__}\")\n",
        "print(f\"ğŸ’» CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "id": "Jzs4z4Vxn8Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageNetClassifier:\n",
        "    \"\"\"ImageNet ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•œ 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ê¸°\"\"\"\n"
      ],
      "metadata": {
        "id": "mUfjCy_Kn8IG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class(í´ë˜ìŠ¤) = ë¶•ì–´ë¹µ íˆ´\n",
        "\n",
        "object(ê°ì²´) = ì‹¤ì œ ë¶•ì–´ë¹µ\n",
        "\n",
        "\n",
        "class(í´ë˜ìŠ¤)ì˜ êµ¬ì„± ìš”ì†Œ:\n",
        "\n",
        "1.attribute(ì†ì„±): ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” variable(ë³€ìˆ˜)\n",
        "\n",
        "2.method(ë©”ì„œë“œ): íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” function(í•¨ìˆ˜)\n"
      ],
      "metadata": {
        "id": "KHWm0wMUtOzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def __init__(self, model_name='resnet50'):\n",
        "        print(f\"ğŸ§  {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"ğŸ’» ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}\")\n",
        "\n",
        "        # ëª¨ë¸ ë¡œë“œ\n",
        "        self.model = self.load_model(model_name)\n",
        "        self.model.eval()  # í‰ê°€ ëª¨ë“œ\n",
        "\n",
        "        # ImageNet í´ë˜ìŠ¤ ë¼ë²¨ ë¡œë“œ\n",
        "        self.class_labels = self.load_imagenet_labels()\n",
        "\n",
        "        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì„¤ì •(ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ì‚¬ì§„ì˜ ì‚¬ì´ì¦ˆê°€ í¬ê¸° ë•Œë¬¸ì— resizeí•¨)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        print(f\"âœ… {model_name} ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "        print(f\"ğŸ“Š ë¶„ë¥˜ ê°€ëŠ¥í•œ í´ë˜ìŠ¤: 1000ê°œ\")"
      ],
      "metadata": {
        "id": "TpC-xd7In8Fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `__init__(self, model_name='resnet50')` method(ë©”ì„œë“œ)ëŠ” class(í´ë˜ìŠ¤)ì˜ **constructor(ìƒì„±ì)**ë¡œ, object(ê°ì²´) ì´ˆê¸°í™”ë¥¼ ë‹´ë‹¹í•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def __init__(self, model_name='resnet50'):\n",
        "   ```\n",
        "   - `model_name`: default parameter(ê¸°ë³¸ ë§¤ê°œë³€ìˆ˜)ë¡œ 'resnet50' ì„¤ì •\n",
        "   - object(ê°ì²´) ìƒì„± ì‹œ ìë™ í˜¸ì¶œ\n",
        "\n",
        "2. **Device selection(ë””ë°”ì´ìŠ¤ ì„ íƒ)**:\n",
        "   ```python\n",
        "   self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "   ```\n",
        "   - `torch.cuda.is_available()`: GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "   - **Conditional expression(ì¡°ê±´ í‘œí˜„ì‹)**: GPU ìˆìœ¼ë©´ 'cuda', ì—†ìœ¼ë©´ 'cpu'\n",
        "   - `self.device`: instance variable(ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜)ë¡œ device ì •ë³´ ì €ì¥\n",
        "\n",
        "3. **Model loading(ëª¨ë¸ ë¡œë”©)**:\n",
        "   ```python\n",
        "   self.model = self.load_model(model_name)\n",
        "   self.model.eval()  # í‰ê°€ ëª¨ë“œ\n",
        "   ```\n",
        "   - `load_model()`: ì•ì„œ ì •ì˜í•œ method(ë©”ì„œë“œ) í˜¸ì¶œ\n",
        "   - `eval()`: evaluation mode(í‰ê°€ ëª¨ë“œ) ì„¤ì • (dropout, batch normalization ë¹„í™œì„±í™”)\n",
        "\n",
        "4. **Labels loading(ë ˆì´ë¸” ë¡œë”©)**:\n",
        "   ```python\n",
        "   self.class_labels = self.load_imagenet_labels()\n",
        "   ```\n",
        "   - ImageNet 1,000ê°œ class labels(í´ë˜ìŠ¤ ë ˆì´ë¸”) ë¡œë”©\n",
        "\n",
        "5. **Image preprocessing pipeline(ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸)**:\n",
        "   ```python\n",
        "   self.transform = transforms.Compose([\n",
        "       transforms.Resize(256),              # 256x256ìœ¼ë¡œ resize(í¬ê¸° ì¡°ì •)\n",
        "       transforms.CenterCrop(224),          # ì¤‘ì•™ì—ì„œ 224x224 crop(ìë¥´ê¸°)\n",
        "       transforms.ToTensor(),               # PIL Image â†’ Tensor ë³€í™˜\n",
        "       transforms.Normalize(mean=[0.485, 0.456, 0.406],  # RGB ì •ê·œí™”\n",
        "                          std=[0.229, 0.224, 0.225])\n",
        "   ])\n",
        "   ```\n",
        "\n",
        "6. **Normalization values(ì •ê·œí™” ê°’ë“¤)**:\n",
        "   ```python\n",
        "   mean=[0.485, 0.456, 0.406],  # ImageNet RGB mean(í‰ê· )\n",
        "   std=[0.229, 0.224, 0.225]    # ImageNet RGB std(í‘œì¤€í¸ì°¨)\n",
        "   ```\n",
        "   - ImageNet dataset(ë°ì´í„°ì…‹)ì—ì„œ ê³„ì‚°ëœ statistical values(í†µê³„ì  ê°’)\n",
        "   - pre-trained model(ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸)ê³¼ ë™ì¼í•œ normalization(ì •ê·œí™”) ì ìš©\n",
        "\n",
        "**ì£¼ì„ ë¶„ì„:**\n",
        "- \"ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” ì‚¬ì§„ì˜ ì‚¬ì´ì¦ˆê°€ í¬ê¸° ë•Œë¬¸ì— resizeí•¨\" â†’ large image files(í° ì´ë¯¸ì§€ íŒŒì¼) ì²˜ë¦¬ë¥¼ ìœ„í•œ resize í•„ìš”ì„±\n",
        "\n",
        "**ì´ˆê¸°í™” ìˆœì„œ:**\n",
        "1. Device ì„¤ì • (GPU/CPU)\n",
        "2. Model ë¡œë”© ë° evaluation mode ì„¤ì •\n",
        "3. Class labels ë¡œë”©\n",
        "4. Image preprocessing pipeline ì„¤ì •\n",
        "5. ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥\n",
        "\n",
        "**Instance variables(ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜):**\n",
        "- `self.device`: ì‚¬ìš©í•  computing device(ì»´í“¨íŒ… ë””ë°”ì´ìŠ¤)\n",
        "- `self.model`: ë¡œë”©ëœ neural network model(ì‹ ê²½ë§ ëª¨ë¸)\n",
        "- `self.class_labels`: ImageNet class names(í´ë˜ìŠ¤ ì´ë¦„ë“¤)\n",
        "- `self.transform`: image preprocessing pipeline(ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸)"
      ],
      "metadata": {
        "id": "O8q8BY2SwS5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def __init__(self, model_name='resnet50'):\n",
        "\n",
        "ì´ í•¨ìˆ˜ëŠ” classì˜ constructorì´ë‹¤\n",
        "\n",
        "##__init__\n",
        "\n",
        "Pythonì˜ special method(íŠ¹ìˆ˜ ë©”ì„œë“œ) ë˜ëŠ” magic method(ë§¤ì§ ë©”ì„œë“œ)\n",
        "\n",
        "object(ê°ì²´)ê°€ ìƒì„±ë  ë•Œ ìë™ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” initialization method(ì´ˆê¸°í™” ë©”ì„œë“œ)\n",
        "\n",
        "constructor(ìƒì„±ì)ë¼ê³ ë„ ë¶€ë¦„tialization method(ì´ˆê¸°í™” ë©”ì„œë“œ)\n",
        "\n",
        "##self\n",
        "ìƒì„±ë˜ëŠ” object(ê°ì²´) ìì‹ ì„ ê°€ë¦¬í‚¤ëŠ” reference(ì°¸ì¡°)\n",
        "\n",
        "ëª¨ë“  method(ë©”ì„œë“œ)ì˜ ì²« ë²ˆì§¸ parameter(ë§¤ê°œë³€ìˆ˜)ë¡œ ì‚¬ìš©\n",
        "\n",
        "instance(ì¸ìŠ¤í„´ìŠ¤) ìì‹ ì„ ì˜ë¯¸\n",
        "\n",
        "##model_name='resnet50'\n",
        "\n",
        "parameter(ë§¤ê°œë³€ìˆ˜) ë˜ëŠ” argument(ì¸ìˆ˜)"
      ],
      "metadata": {
        "id": "26Sh5Fw_t7KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mobilenet_v2 ì°¨ì„ ì¸ì‹í•  ë•Œ ì‚¬ìš©í•¨\n",
        "#ë‹¤ì–‘í•œ ëª¨ë¸ ì‚¬ìš©\n",
        "    def load_model(self, model_name):\n",
        "        \"\"\"ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
        "        models_dict = {\n",
        "            'resnet50': models.resnet50(pretrained=True),\n",
        "            'resnet101': models.resnet101(pretrained=True),\n",
        "            'vgg16': models.vgg16(pretrained=True),\n",
        "            'vgg19': models.vgg19(pretrained=True),\n",
        "            'densenet121': models.densenet121(pretrained=True),\n",
        "            'efficientnet_b0': models.efficientnet_b0(pretrained=True),\n",
        "            'mobilenet_v2': models.mobilenet_v2(pretrained=True),\n",
        "            'alexnet': models.alexnet(pretrained=True),\n",
        "            'inception_v3': models.inception_v3(pretrained=True)\n",
        "        }\n",
        "\n",
        "        if model_name not in models_dict:\n",
        "            print(f\"âš ï¸ {model_name} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ResNet50ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "            model_name = 'resnet50'\n",
        "\n",
        "        model = models_dict[model_name]\n",
        "        return model.to(self.device)\n"
      ],
      "metadata": {
        "id": "p8f8NMSYn8Cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `load_model(self, model_name)` method(ë©”ì„œë“œ)ëŠ” ë‹¤ì–‘í•œ pre-trained models(ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸)ì„ ë¡œë”©í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def load_model(self, model_name):\n",
        "   ```\n",
        "   - `model_name`: ë¡œë“œí•  model(ëª¨ë¸)ì˜ ì´ë¦„ì„ ë°›ëŠ” parameter(ë§¤ê°œë³€ìˆ˜)\n",
        "\n",
        "2. **Models dictionary(ëª¨ë¸ ë”•ì…”ë„ˆë¦¬)**:\n",
        "   ```python\n",
        "   models_dict = {\n",
        "       'resnet50': models.resnet50(pretrained=True),\n",
        "       'resnet101': models.resnet101(pretrained=True),\n",
        "       # ... ë‹¤ë¥¸ ëª¨ë¸ë“¤\n",
        "   }\n",
        "   ```\n",
        "   - dictionary(ë”•ì…”ë„ˆë¦¬) í˜•íƒœë¡œ multiple models(ì—¬ëŸ¬ ëª¨ë¸) ì €ì¥\n",
        "   - `pretrained=True`: ImageNetì—ì„œ pre-trained weights(ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜) ì‚¬ìš©\n",
        "\n",
        "3. **Available models(ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤)**:\n",
        "   - **ResNet**: `resnet50`, `resnet101` - residual networks(ì”ì°¨ ë„¤íŠ¸ì›Œí¬)\n",
        "   - **VGG**: `vgg16`, `vgg19` - Visual Geometry Group models(ì‹œê° ê¸°í•˜í•™ ê·¸ë£¹ ëª¨ë¸)\n",
        "   - **DenseNet**: `densenet121` - densely connected networks(ë°€ì§‘ ì—°ê²° ë„¤íŠ¸ì›Œí¬)\n",
        "   - **EfficientNet**: `efficientnet_b0` - efficient neural networks(íš¨ìœ¨ì ì¸ ì‹ ê²½ë§)\n",
        "   - **MobileNet**: `mobilenet_v2` - mobile-optimized networks(ëª¨ë°”ì¼ ìµœì í™” ë„¤íŠ¸ì›Œí¬)\n",
        "   - **AlexNet**: `alexnet` - classic CNN architecture(í´ë˜ì‹ CNN êµ¬ì¡°)\n",
        "   - **Inception**: `inception_v3` - Google's Inception architecture(êµ¬ê¸€ì˜ ì¸ì…‰ì…˜ êµ¬ì¡°)\n",
        "\n",
        "4. **Error handling(ì—ëŸ¬ ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   if model_name not in models_dict:\n",
        "       print(f\"âš ï¸ {model_name} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ResNet50ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "       model_name = 'resnet50'\n",
        "   ```\n",
        "   - invalid model name(ì˜ëª»ëœ ëª¨ë¸ ì´ë¦„) ì‹œ default(ê¸°ë³¸ê°’)ë¡œ ResNet50 ì‚¬ìš©\n",
        "\n",
        "5. **Model loading and device transfer(ëª¨ë¸ ë¡œë”© ë° ë””ë°”ì´ìŠ¤ ì „ì†¡)**:\n",
        "   ```python\n",
        "   model = models_dict[model_name]\n",
        "   return model.to(self.device)\n",
        "   ```\n",
        "   - ì„ íƒëœ model(ëª¨ë¸) ë¡œë”©\n",
        "   - `to(self.device)`: model(ëª¨ë¸)ì„ specified device(ì§€ì •ëœ ë””ë°”ì´ìŠ¤)ë¡œ ì´ë™ (CPU/GPU)\n",
        "\n",
        "**ì£¼ì„ ë¶„ì„:**\n",
        "- \"mobilenet_v2 ì°¨ì„ ì¸ì‹í•  ë•Œ ì‚¬ìš©í•¨\" â†’ lane detection(ì°¨ì„  ì¸ì‹) project(í”„ë¡œì íŠ¸)ì—ì„œ MobileNet V2 ì‚¬ìš©\n",
        "- \"ë‹¤ì–‘í•œ ëª¨ë¸ ì‚¬ìš©\" â†’ multiple model architectures(ì—¬ëŸ¬ ëª¨ë¸ êµ¬ì¡°) ì§€ì›\n",
        "\n",
        "**ì‚¬ìš© ì˜ˆì‹œ:**\n",
        "```python\n",
        "model = self.load_model('mobilenet_v2')  # MobileNet V2 ë¡œë”©\n",
        "model = self.load_model('resnet50')      # ResNet-50 ë¡œë”©\n",
        "```\n",
        "\n",
        "**return value(ë°˜í™˜ê°’)**: ì§€ì •ëœ device(ë””ë°”ì´ìŠ¤)ì— ë¡œë”©ëœ PyTorch model(íŒŒì´í† ì¹˜ ëª¨ë¸)"
      ],
      "metadata": {
        "id": "q2tZSQxtu2Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def load_imagenet_labels(self):\n",
        "        \"\"\"ImageNet 1000ê°œ í´ë˜ìŠ¤ ë¼ë²¨ ë¡œë“œ\"\"\"\n",
        "        try:\n",
        "            # ImageNet í´ë˜ìŠ¤ ë¼ë²¨ ë‹¤ìš´ë¡œë“œ, ë‹¤ì–‘í•œ ì°¨ì„ ì€ ëª¨ë‘ ê°ê° ë¼ë²¨ë§ í•´ì•¼í•¨\n",
        "            url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "            response = requests.get(url)\n",
        "            labels = response.text.strip().split('\\n')\n",
        "            print(f\"ğŸ“‹ ImageNet ë¼ë²¨ ë¡œë“œ ì™„ë£Œ: {len(labels)}ê°œ\")\n",
        "            return labels\n",
        "        except:\n",
        "            print(\"âš ï¸ ì˜¨ë¼ì¸ ë¼ë²¨ ë¡œë“œ ì‹¤íŒ¨. ê¸°ë³¸ ë¼ë²¨ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "            # ì¼ë¶€ ì£¼ìš” í´ë˜ìŠ¤ë§Œ í¬í•¨í•œ ê¸°ë³¸ ë¼ë²¨\n",
        "            return [f\"class_{i}\" for i in range(1000)]"
      ],
      "metadata": {
        "id": "ljd-kTRGn8AJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `load_imagenet_labels(self)` method(ë©”ì„œë“œ)ëŠ” ImageNetì˜ 1,000ê°œ class labels(í´ë˜ìŠ¤ ë ˆì´ë¸”)ì„ ë¡œë”©í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def load_imagenet_labels(self):\n",
        "   ```\n",
        "   - parameter(ë§¤ê°œë³€ìˆ˜) ì—†ì´ selfë§Œ ë°›ìŒ\n",
        "   - return value(ë°˜í™˜ê°’)ë¡œ labels list(ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸) ë°˜í™˜\n",
        "\n",
        "2. **Try-except block(ì˜ˆì™¸ ì²˜ë¦¬ ë¸”ë¡)**:\n",
        "   ```python\n",
        "   try:\n",
        "       # ì˜¨ë¼ì¸ì—ì„œ ë¼ë²¨ ë‹¤ìš´ë¡œë“œ ì‹œë„\n",
        "   except:\n",
        "       # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¼ë²¨ ì‚¬ìš©\n",
        "   ```\n",
        "\n",
        "3. **Online label loading(ì˜¨ë¼ì¸ ë¼ë²¨ ë¡œë”©)**:\n",
        "   ```python\n",
        "   url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "   response = requests.get(url)\n",
        "   labels = response.text.strip().split('\\n')\n",
        "   ```\n",
        "   - GitHubì—ì„œ official ImageNet labels(ê³µì‹ ImageNet ë ˆì´ë¸”) ë‹¤ìš´ë¡œë“œ\n",
        "   - `strip()`: ì•ë’¤ whitespace(ê³µë°±) ì œê±°\n",
        "   - `split('\\n')`: newline character(ì¤„ë°”ê¿ˆ ë¬¸ì)ë¡œ ë¶„í• í•´ì„œ list(ë¦¬ìŠ¤íŠ¸)ë¡œ ë³€í™˜\n",
        "\n",
        "4. **Success logging(ì„±ê³µ ë¡œê¹…)**:\n",
        "   ```python\n",
        "   print(f\"ğŸ“‹ ImageNet ë¼ë²¨ ë¡œë“œ ì™„ë£Œ: {len(labels)}ê°œ\")\n",
        "   ```\n",
        "   - f-string formatting(í¬ë§·íŒ…)ìœ¼ë¡œ loaded labels count(ë¡œë“œëœ ë ˆì´ë¸” ê°œìˆ˜) ì¶œë ¥\n",
        "\n",
        "5. **Fallback mechanism(ëŒ€ì²´ ë©”ì»¤ë‹ˆì¦˜)**:\n",
        "   ```python\n",
        "   return [f\"class_{i}\" for i in range(1000)]\n",
        "   ```\n",
        "   - List comprehension(ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜)ìœ¼ë¡œ generic labels(ì¼ë°˜ì ì¸ ë ˆì´ë¸”) ìƒì„±\n",
        "   - network error(ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬) ì‹œ `class_0`, `class_1`, ..., `class_999` í˜•íƒœ\n",
        "\n",
        "**ì£¼ì„ ë¶„ì„:**\n",
        "- \"ë‹¤ì–‘í•œ ì°¨ì„ ì€ ëª¨ë‘ ê°ê° ë¼ë²¨ë§ í•´ì•¼í•¨\" â†’ ì•„ë§ˆë„ traffic/road classification(êµí†µ/ë„ë¡œ ë¶„ë¥˜) project(í”„ë¡œì íŠ¸)ì—ì„œ ì‚¬ìš©\n",
        "\n",
        "**ì‹¤ì œ ImageNet labels ì˜ˆì‹œ:**\n",
        "- Index 0: 'tench' (í…ì¹˜, ë¬¼ê³ ê¸° ì¢…ë¥˜)\n",
        "- Index 281: 'tabby cat' (ì–¼ë£© ê³ ì–‘ì´)  \n",
        "- Index 285: 'Egyptian cat' (ì´ì§‘íŠ¸ ê³ ì–‘ì´)\n",
        "\n",
        "**return value(ë°˜í™˜ê°’)**: 1,000ê°œ string(ë¬¸ìì—´) ìš”ì†Œë¥¼ ê°€ì§„ list(ë¦¬ìŠ¤íŠ¸)"
      ],
      "metadata": {
        "id": "D9Fz7uhcvsvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def load_image(self, image_source):\n",
        "        \"\"\"ì´ë¯¸ì§€ ë¡œë“œ (íŒŒì¼ ê²½ë¡œ ë˜ëŠ” URL)\"\"\"\n",
        "        try:\n",
        "            if isinstance(image_source, str):\n",
        "                if image_source.startswith('http'):\n",
        "                    # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
        "                    response = requests.get(image_source)\n",
        "                    image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "                else:\n",
        "                    # ë¡œì»¬ íŒŒì¼\n",
        "                    image = Image.open(image_source).convert('RGB')\n",
        "            else:\n",
        "                # PIL Image ê°ì²´\n",
        "                image = image_source.convert('RGB')\n",
        "\n",
        "            return image\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "8B-46LKgn79Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `load_image(self, image_source)` method(ë©”ì„œë“œ)ëŠ” ë‹¤ì–‘í•œ source(ì†ŒìŠ¤)ì—ì„œ image(ì´ë¯¸ì§€)ë¥¼ ë¡œë”©í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def load_image(self, image_source):\n",
        "   ```\n",
        "   - `image_source`: ì´ë¯¸ì§€ ì†ŒìŠ¤ (file path(íŒŒì¼ ê²½ë¡œ), URL, ë˜ëŠ” PIL Image object(ê°ì²´))\n",
        "\n",
        "2. **Input type checking(ì…ë ¥ íƒ€ì… ì²´í¬)**:\n",
        "   ```python\n",
        "   if isinstance(image_source, str):\n",
        "   ```\n",
        "   - `isinstance()`: object(ê°ì²´)ì˜ type(íƒ€ì…) í™•ì¸\n",
        "   - string(ë¬¸ìì—´)ì¸ì§€ í™•ì¸ (file path ë˜ëŠ” URL)\n",
        "\n",
        "3. **URL handling(URL ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   if image_source.startswith('http'):\n",
        "       response = requests.get(image_source)\n",
        "       image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "   ```\n",
        "   - `startswith('http')`: URL ì—¬ë¶€ í™•ì¸\n",
        "   - `requests.get()`: HTTP request(ìš”ì²­)ë¡œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
        "   - `BytesIO()`: bytes data(ë°”ì´íŠ¸ ë°ì´í„°)ë¥¼ file-like object(íŒŒì¼ ìœ ì‚¬ ê°ì²´)ë¡œ ë³€í™˜\n",
        "   - `Image.open()`: PIL Image object(ê°ì²´) ìƒì„±\n",
        "   - `convert('RGB')`: color mode(ìƒ‰ìƒ ëª¨ë“œ)ë¥¼ RGBë¡œ ë³€í™˜\n",
        "\n",
        "4. **Local file handling(ë¡œì»¬ íŒŒì¼ ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   else:\n",
        "       image = Image.open(image_source).convert('RGB')\n",
        "   ```\n",
        "   - ë¡œì»¬ file path(íŒŒì¼ ê²½ë¡œ)ì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ë¡œë”©\n",
        "\n",
        "5. **PIL Image object handling(PIL ì´ë¯¸ì§€ ê°ì²´ ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   else:\n",
        "       image = image_source.convert('RGB')\n",
        "   ```\n",
        "   - ì´ë¯¸ PIL Image object(ê°ì²´)ì¸ ê²½ìš° RGBë¡œë§Œ ë³€í™˜\n",
        "\n",
        "6. **Error handling(ì—ëŸ¬ ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   except Exception as e:\n",
        "       print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "       return None\n",
        "   ```\n",
        "   - ëª¨ë“  exception(ì˜ˆì™¸) ì²˜ë¦¬\n",
        "   - ì‹¤íŒ¨ ì‹œ `None` ë°˜í™˜\n",
        "\n",
        "**ì‚¬ìš© ì˜ˆì‹œ:**\n",
        "```python\n",
        "# URLì—ì„œ ë¡œë”©\n",
        "image1 = self.load_image(\"https://example.com/cat.jpg\")\n",
        "\n",
        "# ë¡œì»¬ íŒŒì¼ì—ì„œ ë¡œë”©\n",
        "image2 = self.load_image(\"./images/dog.png\")\n",
        "\n",
        "# PIL Image objectì—ì„œ ë¡œë”©\n",
        "pil_image = Image.open(\"photo.jpg\")\n",
        "image3 = self.load_image(pil_image)\n",
        "```\n",
        "\n",
        "**return value(ë°˜í™˜ê°’)**: PIL Image object(ê°ì²´) ë˜ëŠ” `None` (ì‹¤íŒ¨ ì‹œ)"
      ],
      "metadata": {
        "id": "YSEnXWGEvdUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   def preprocess_image(self, image):\n",
        "        \"\"\"ì´ë¯¸ì§€ ì „ì²˜ë¦¬\"\"\"\n",
        "        if image is None:\n",
        "            return None\n",
        "\n",
        "        # PIL Image â†’ Tensor\n",
        "        tensor = self.transform(image).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
        "        return tensor.to(self.device)\n"
      ],
      "metadata": {
        "id": "9Rixcze0n766"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `preprocess_image(self, image)` method(ë©”ì„œë“œ)ëŠ” raw image(ì›ë³¸ ì´ë¯¸ì§€)ë¥¼ model input(ëª¨ë¸ ì…ë ¥) í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def preprocess_image(self, image):\n",
        "   ```\n",
        "   - `image`: PIL Image object(ê°ì²´) ë˜ëŠ” Noneì„ ë°›ëŠ” parameter(ë§¤ê°œë³€ìˆ˜)\n",
        "\n",
        "2. **Null check(ë„ ì²´í¬)**:\n",
        "   ```python\n",
        "   if image is None:\n",
        "       return None\n",
        "   ```\n",
        "   - input validation(ì…ë ¥ ê²€ì¦)ìœ¼ë¡œ None ê°’ ì²˜ë¦¬\n",
        "\n",
        "3. **Image transformation(ì´ë¯¸ì§€ ë³€í™˜)**:\n",
        "   ```python\n",
        "   tensor = self.transform(image).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
        "   ```\n",
        "   - `self.transform(image)`: constructor(ìƒì„±ì)ì—ì„œ ì •ì˜í•œ preprocessing pipeline(ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸) ì ìš©\n",
        "   - `unsqueeze(0)`: batch dimension(ë°°ì¹˜ ì°¨ì›) ì¶”ê°€\n",
        "   - shape ë³€í™”: `[C, H, W]` â†’ `[1, C, H, W]`\n",
        "\n",
        "4. **Device transfer(ë””ë°”ì´ìŠ¤ ì „ì†¡)**:\n",
        "   ```python\n",
        "   return tensor.to(self.device)\n",
        "   ```\n",
        "   - tensor(í…ì„œ)ë¥¼ ì§€ì •ëœ device(ë””ë°”ì´ìŠ¤, CPU/GPU)ë¡œ ì´ë™\n",
        "   - model(ëª¨ë¸)ê³¼ ë™ì¼í•œ deviceì— ìœ„ì¹˜ì‹œí‚´\n",
        "\n",
        "**Transformation pipeline(ë³€í™˜ íŒŒì´í”„ë¼ì¸) ì ìš©:**\n",
        "- `Resize(256)`: ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 256x256ìœ¼ë¡œ ì¡°ì •\n",
        "- `CenterCrop(224)`: ì¤‘ì•™ì—ì„œ 224x224 í¬ê¸°ë¡œ crop(ìë¥´ê¸°)\n",
        "- `ToTensor()`: PIL Image â†’ PyTorch Tensor ë³€í™˜, [0,255] â†’ [0,1] ì •ê·œí™”\n",
        "- `Normalize()`: ImageNet statistics(í†µê³„)ë¡œ ì •ê·œí™”\n",
        "\n",
        "**Tensor shape(í…ì„œ í˜•íƒœ):**\n",
        "- Input: PIL Image (H, W, C)\n",
        "- After transform: Tensor (C, H, W) = (3, 224, 224)\n",
        "- After unsqueeze: Tensor (1, C, H, W) = (1, 3, 224, 224)\n",
        "\n",
        "**return value(ë°˜í™˜ê°’)**:\n",
        "- Success: preprocessed tensor(ì „ì²˜ë¦¬ëœ í…ì„œ) on specified device(ì§€ì •ëœ ë””ë°”ì´ìŠ¤)\n",
        "- Failure: None\n",
        "\n",
        "**ì—­í• :**\n",
        "- Raw image(ì›ë³¸ ì´ë¯¸ì§€)ë¥¼ neural network(ì‹ ê²½ë§) input format(ì…ë ¥ í˜•ì‹)ìœ¼ë¡œ ë³€í™˜\n",
        "- Model inference(ëª¨ë¸ ì¶”ë¡ )ì„ ìœ„í•œ ì¤€ë¹„ ì‘ì—…"
      ],
      "metadata": {
        "id": "TSuE9123wg39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def predict(self, image_source, top_k=5):\n",
        "        \"\"\"ì´ë¯¸ì§€ ë¶„ë¥˜ ì˜ˆì¸¡\"\"\"\n",
        "        print(f\"ğŸ” ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...\")\n",
        "\n",
        "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        image = self.load_image(image_source)\n",
        "        if image is None:\n",
        "            return None\n",
        "\n",
        "        original_image = image.copy()\n",
        "\n",
        "        # ì „ì²˜ë¦¬\n",
        "        input_tensor = self.preprocess_image(image)\n",
        "        if input_tensor is None:\n",
        "            return None\n",
        "\n",
        "        # ì˜ˆì¸¡ torch.no_grad(): ì´ëŸ° ëª¨ë¥´ëŠ” ìš©ì–´ ì •ë¦¬í•˜ê¸°, í•¨ìˆ˜ë³„ë¡œ ìª¼ê°œì„œ ì„¤ëª…, ì£¼ì„ ë‹¬ê¸°\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "\n",
        "        # Top-K ê²°ê³¼ ì¶”ì¶œ\n",
        "        top_prob, top_indices = torch.topk(probabilities, top_k)\n",
        "\n",
        "        results = []\n",
        "        for i in range(top_k):\n",
        "            class_idx = top_indices[i].item()\n",
        "            prob = top_prob[i].item()\n",
        "            class_name = self.class_labels[class_idx]\n",
        "            results.append({\n",
        "                'rank': i + 1,\n",
        "                'class_index': class_idx,\n",
        "                'class_name': class_name,\n",
        "                'probability': prob,\n",
        "                'percentage': prob * 100\n",
        "            })\n",
        "\n",
        "        return {\n",
        "            'original_image': original_image,\n",
        "            'predictions': results,\n",
        "            'model_info': {\n",
        "                'model_name': self.model.__class__.__name__,\n",
        "                'device': str(self.device),\n",
        "                'total_classes': len(self.class_labels)\n",
        "            }\n",
        "        }\n"
      ],
      "metadata": {
        "id": "UxIamVVvn74p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `predict(self, image_source, top_k=5)` method(ë©”ì„œë“œ)ëŠ” ì´ë¯¸ì§€ ë¶„ë¥˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” main function(ë©”ì¸ í•¨ìˆ˜)ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def predict(self, image_source, top_k=5):\n",
        "   ```\n",
        "   - `image_source`: ì´ë¯¸ì§€ ì†ŒìŠ¤ (file path, URL, PIL Image)\n",
        "   - `top_k=5`: ìƒìœ„ ëª‡ ê°œ ê²°ê³¼ë¥¼ ë°˜í™˜í• ì§€ ê²°ì •í•˜ëŠ” parameter(ë§¤ê°œë³€ìˆ˜)\n",
        "\n",
        "2. **Image loading(ì´ë¯¸ì§€ ë¡œë”©)**:\n",
        "   ```python\n",
        "   image = self.load_image(image_source)\n",
        "   if image is None:\n",
        "       return None\n",
        "   original_image = image.copy()\n",
        "   ```\n",
        "   - `load_image()`: ì´ë¯¸ì§€ ë¡œë”© method(ë©”ì„œë“œ) í˜¸ì¶œ\n",
        "   - `copy()`: original image(ì›ë³¸ ì´ë¯¸ì§€) ë°±ì—… ì €ì¥\n",
        "\n",
        "3. **Image preprocessing(ì´ë¯¸ì§€ ì „ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   input_tensor = self.preprocess_image(image)\n",
        "   if input_tensor is None:\n",
        "       return None\n",
        "   ```\n",
        "   - `preprocess_image()`: ì´ë¯¸ì§€ë¥¼ model input format(ëª¨ë¸ ì…ë ¥ í˜•ì‹)ìœ¼ë¡œ ë³€í™˜\n",
        "\n",
        "4. **Model inference(ëª¨ë¸ ì¶”ë¡ )**:\n",
        "   ```python\n",
        "   with torch.no_grad():\n",
        "       outputs = self.model(input_tensor)\n",
        "       probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
        "   ```\n",
        "   - `torch.no_grad()`: gradient calculation(ê¸°ìš¸ê¸° ê³„ì‚°) ë¹„í™œì„±í™”, memory efficiency(ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±) í–¥ìƒ\n",
        "   - `self.model(input_tensor)`: forward pass(ìˆœì „íŒŒ) ì‹¤í–‰\n",
        "   - `softmax()`: raw output(ì›ì‹œ ì¶œë ¥)ì„ probability distribution(í™•ë¥  ë¶„í¬)ë¡œ ë³€í™˜\n",
        "   - `dim=0`: ì²« ë²ˆì§¸ ì°¨ì›(class dimension)ì—ì„œ softmax ì ìš©\n",
        "\n",
        "5. **Top-K results extraction(ìƒìœ„ Kê°œ ê²°ê³¼ ì¶”ì¶œ)**:\n",
        "   ```python\n",
        "   top_prob, top_indices = torch.topk(probabilities, top_k)\n",
        "   ```\n",
        "   - `torch.topk()`: ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ top_kê°œ ê°’ê³¼ index(ì¸ë±ìŠ¤) ë°˜í™˜\n",
        "   - `top_prob`: ìƒìœ„ í™•ë¥ ê°’ë“¤\n",
        "   - `top_indices`: í•´ë‹¹ class index(í´ë˜ìŠ¤ ì¸ë±ìŠ¤)ë“¤\n",
        "\n",
        "6. **Results formatting(ê²°ê³¼ í¬ë§·íŒ…)**:\n",
        "   ```python\n",
        "   results = []\n",
        "   for i in range(top_k):\n",
        "       class_idx = top_indices[i].item()\n",
        "       prob = top_prob[i].item()\n",
        "       class_name = self.class_labels[class_idx]\n",
        "       results.append({\n",
        "           'rank': i + 1,\n",
        "           'class_index': class_idx,\n",
        "           'class_name': class_name,\n",
        "           'probability': prob,\n",
        "           'percentage': prob * 100\n",
        "       })\n",
        "   ```\n",
        "   - `item()`: tensor scalar(í…ì„œ ìŠ¤ì¹¼ë¼)ë¥¼ Python number(íŒŒì´ì¬ ìˆ«ì)ë¡œ ë³€í™˜\n",
        "   - dictionary format(ë”•ì…”ë„ˆë¦¬ í˜•ì‹)ìœ¼ë¡œ ê²°ê³¼ êµ¬ì„±\n",
        "\n",
        "7. **Return value(ë°˜í™˜ê°’)**:\n",
        "   ```python\n",
        "   return {\n",
        "       'original_image': original_image,\n",
        "       'predictions': results,\n",
        "       'model_info': {\n",
        "           'model_name': self.model.__class__.__name__,\n",
        "           'device': str(self.device),\n",
        "           'total_classes': len(self.class_labels)\n",
        "       }\n",
        "   }\n",
        "   ```\n",
        "   - structured output(êµ¬ì¡°í™”ëœ ì¶œë ¥): ì›ë³¸ ì´ë¯¸ì§€, ì˜ˆì¸¡ ê²°ê³¼, ëª¨ë¸ ì •ë³´ í¬í•¨\n",
        "\n",
        "**ì£¼ìš” í•¨ìˆ˜ ì„¤ëª…:**\n",
        "- `torch.no_grad()`: inference(ì¶”ë¡ ) ì‹œ gradient computation(ê¸°ìš¸ê¸° ê³„ì‚°) ë¹„í™œì„±í™”\n",
        "- `torch.nn.functional.softmax()`: logitsì„ probability(í™•ë¥ )ë¡œ ë³€í™˜\n",
        "- `torch.topk()`: tensorì—ì„œ ê°€ì¥ í° kê°œ ê°’ê³¼ index ì¶”ì¶œ\n",
        "- `item()`: single-element tensorë¥¼ Python scalarë¡œ ë³€í™˜"
      ],
      "metadata": {
        "id": "agS1G5thwqll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(self, results, show_top_k=5):\n",
        "        \"\"\"ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
        "        if results is None:\n",
        "            print(\"âŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return\n",
        "\n",
        "        # ê²°ê³¼ ì¶œë ¥\n",
        "        print(f\"\\nğŸ¯ ImageNet ë¶„ë¥˜ ê²°ê³¼ (Top {show_top_k}):\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        predictions = results['predictions'][:show_top_k]\n",
        "\n",
        "        for pred in predictions:\n",
        "            print(f\"{pred['rank']}. {pred['class_name']:<30} {pred['percentage']:.2f}%\")\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # ì‹œê°í™”\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "        # ì›ë³¸ ì´ë¯¸ì§€\n",
        "        ax1.imshow(results['original_image'])\n",
        "        ax1.set_title('Original Image', fontsize=14, fontweight='bold')\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # ì˜ˆì¸¡ ê²°ê³¼ ë§‰ëŒ€ ê·¸ë˜í”„\n",
        "        class_names = [pred['class_name'][:20] for pred in predictions]  # ì´ë¦„ ê¸¸ì´ ì œí•œ\n",
        "        probabilities = [pred['percentage'] for pred in predictions]\n",
        "        colors = plt.cm.viridis(np.linspace(0, 1, len(predictions)))\n",
        "\n",
        "        bars = ax2.barh(range(len(predictions)), probabilities, color=colors)\n",
        "        ax2.set_yticks(range(len(predictions)))\n",
        "        ax2.set_yticklabels(class_names)\n",
        "        ax2.set_xlabel('Confidence (%)')\n",
        "        ax2.set_title(f'Top {show_top_k} Predictions', fontsize=14, fontweight='bold')\n",
        "        ax2.invert_yaxis()  # ë†’ì€ í™•ë¥ ì´ ìœ„ë¡œ\n",
        "\n",
        "        # ë§‰ëŒ€ì— í¼ì„¼íŠ¸ í‘œì‹œ\n",
        "        for i, (bar, prob) in enumerate(zip(bars, probabilities)):\n",
        "            ax2.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
        "                    f'{prob:.1f}%', va='center', fontweight='bold')\n",
        "\n",
        "        # ì „ì²´ ì œëª©\n",
        "        best_prediction = predictions[0]\n",
        "        plt.suptitle(f'ğŸ† Best Prediction: {best_prediction[\"class_name\"]} ({best_prediction[\"percentage\"]:.1f}%)',\n",
        "                    fontsize=16, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # ëª¨ë¸ ì •ë³´\n",
        "        model_info = results['model_info']\n",
        "        print(f\"\\nğŸ“Š ëª¨ë¸ ì •ë³´:\")\n",
        "        print(f\"   ğŸ§  ëª¨ë¸: {model_info['model_name']}\")\n",
        "        print(f\"   ğŸ’» ë””ë°”ì´ìŠ¤: {model_info['device']}\")\n",
        "        print(f\"   ğŸ“‹ ì´ í´ë˜ìŠ¤ ìˆ˜: {model_info['total_classes']}\")\n"
      ],
      "metadata": {
        "id": "puzlibOgn72R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `visualize_results(self, results, show_top_k=5)` method(ë©”ì„œë“œ)ëŠ” prediction results(ì˜ˆì¸¡ ê²°ê³¼)ë¥¼ ì‹œê°í™”í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def visualize_results(self, results, show_top_k=5):\n",
        "   ```\n",
        "   - `results`: predict() method(ë©”ì„œë“œ)ì—ì„œ ë°˜í™˜ëœ dictionary(ë”•ì…”ë„ˆë¦¬)\n",
        "   - `show_top_k=5`: í‘œì‹œí•  ìƒìœ„ ê²°ê³¼ ê°œìˆ˜\n",
        "\n",
        "2. **Input validation(ì…ë ¥ ê²€ì¦)**:\n",
        "   ```python\n",
        "   if results is None:\n",
        "       print(\"âŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "       return\n",
        "   ```\n",
        "   - None ê°’ ì²˜ë¦¬\n",
        "\n",
        "3. **Text output(í…ìŠ¤íŠ¸ ì¶œë ¥)**:\n",
        "   ```python\n",
        "   predictions = results['predictions'][:show_top_k]\n",
        "   for pred in predictions:\n",
        "       print(f\"{pred['rank']}. {pred['class_name']:<30} {pred['percentage']:.2f}%\")\n",
        "   ```\n",
        "   - `[:show_top_k]`: list slicing(ë¦¬ìŠ¤íŠ¸ ìŠ¬ë¼ì´ì‹±)ìœ¼ë¡œ ìƒìœ„ kê°œë§Œ ì„ íƒ\n",
        "   - `:<30`: left-aligned(ì™¼ìª½ ì •ë ¬) 30ì width(ë„ˆë¹„)\n",
        "   - `:.2f`: ì†Œìˆ˜ì  2ìë¦¬ formatting(í¬ë§·íŒ…)\n",
        "\n",
        "4. **Subplot creation(ì„œë¸Œí”Œë¡¯ ìƒì„±)**:\n",
        "   ```python\n",
        "   fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "   ```\n",
        "   - `subplots(1, 2)`: 1í–‰ 2ì—´ layout(ë ˆì´ì•„ì›ƒ)\n",
        "   - `figsize=(15, 6)`: figure size(ê·¸ë¦¼ í¬ê¸°) ì„¤ì •\n",
        "\n",
        "5. **Original image display(ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ)**:\n",
        "   ```python\n",
        "   ax1.imshow(results['original_image'])\n",
        "   ax1.set_title('Original Image', fontsize=14, fontweight='bold')\n",
        "   ax1.axis('off')\n",
        "   ```\n",
        "   - `imshow()`: image display(ì´ë¯¸ì§€ í‘œì‹œ)\n",
        "   - `axis('off')`: axis labels(ì¶• ë¼ë²¨) ì œê±°\n",
        "\n",
        "6. **Bar chart creation(ë§‰ëŒ€ ê·¸ë˜í”„ ìƒì„±)**:\n",
        "   ```python\n",
        "   class_names = [pred['class_name'][:20] for pred in predictions]\n",
        "   probabilities = [pred['percentage'] for pred in predictions]\n",
        "   colors = plt.cm.viridis(np.linspace(0, 1, len(predictions)))\n",
        "   ```\n",
        "   - `[:20]`: string slicing(ë¬¸ìì—´ ìŠ¬ë¼ì´ì‹±)ìœ¼ë¡œ ì´ë¦„ ê¸¸ì´ ì œí•œ\n",
        "   - `plt.cm.viridis()`: colormap(ì»¬ëŸ¬ë§µ) ì‚¬ìš©\n",
        "   - `np.linspace()`: ê· ë“± ê°„ê²© ìƒ‰ìƒ ìƒì„±\n",
        "\n",
        "7. **Horizontal bar chart(ìˆ˜í‰ ë§‰ëŒ€ ê·¸ë˜í”„)**:\n",
        "   ```python\n",
        "   bars = ax2.barh(range(len(predictions)), probabilities, color=colors)\n",
        "   ax2.set_yticks(range(len(predictions)))\n",
        "   ax2.set_yticklabels(class_names)\n",
        "   ax2.invert_yaxis()  # ë†’ì€ í™•ë¥ ì´ ìœ„ë¡œ\n",
        "   ```\n",
        "   - `barh()`: horizontal bar chart(ìˆ˜í‰ ë§‰ëŒ€ ê·¸ë˜í”„)\n",
        "   - `invert_yaxis()`: yì¶• ìˆœì„œ ë’¤ì§‘ê¸°\n",
        "\n",
        "8. **Text annotations(í…ìŠ¤íŠ¸ ì£¼ì„)**:\n",
        "   ```python\n",
        "   for i, (bar, prob) in enumerate(zip(bars, probabilities)):\n",
        "       ax2.text(bar.get_width() + 0.5, bar.get_y() + bar.get_height()/2,\n",
        "               f'{prob:.1f}%', va='center', fontweight='bold')\n",
        "   ```\n",
        "   - `enumerate()`: indexì™€ value ë™ì‹œ ë°˜ë³µ\n",
        "   - `zip()`: ë‘ listë¥¼ pair(ìŒ)ë¡œ ê²°í•©\n",
        "   - `va='center'`: vertical alignment(ìˆ˜ì§ ì •ë ¬)\n",
        "\n",
        "9. **Title and layout(ì œëª© ë° ë ˆì´ì•„ì›ƒ)**:\n",
        "   ```python\n",
        "   best_prediction = predictions[0]\n",
        "   plt.suptitle(f'ğŸ† Best Prediction: {best_prediction[\"class_name\"]} ({best_prediction[\"percentage\"]:.1f}%)',\n",
        "               fontsize=16, fontweight='bold')\n",
        "   plt.tight_layout()\n",
        "   plt.show()\n",
        "   ```\n",
        "   - `suptitle()`: main title(ë©”ì¸ ì œëª©) ì„¤ì •\n",
        "   - `tight_layout()`: automatic spacing(ìë™ ê°„ê²©) ì¡°ì •\n",
        "   - `show()`: plot display(í”Œë¡¯ í‘œì‹œ)\n",
        "\n",
        "10. **Model information display(ëª¨ë¸ ì •ë³´ í‘œì‹œ)**:\n",
        "    ```python\n",
        "    model_info = results['model_info']\n",
        "    print(f\"   ğŸ§  ëª¨ë¸: {model_info['model_name']}\")\n",
        "    print(f\"   ğŸ’» ë””ë°”ì´ìŠ¤: {model_info['device']}\")\n",
        "    print(f\"   ğŸ“‹ ì´ í´ë˜ìŠ¤ ìˆ˜: {model_info['total_classes']}\")\n",
        "    ```\n",
        "    - metadata(ë©”íƒ€ë°ì´í„°) ì¶œë ¥\n",
        "\n",
        "**ì‹œê°í™” êµ¬ì„±:**\n",
        "- Left panel(ì™¼ìª½ íŒ¨ë„): original image(ì›ë³¸ ì´ë¯¸ì§€)\n",
        "- Right panel(ì˜¤ë¥¸ìª½ íŒ¨ë„): confidence scores(ì‹ ë¢°ë„ ì ìˆ˜) ë§‰ëŒ€ ê·¸ë˜í”„\n",
        "- Text output(í…ìŠ¤íŠ¸ ì¶œë ¥): rankingê³¼ percentage(í¼ì„¼íŠ¸) ì •ë³´"
      ],
      "metadata": {
        "id": "x0k4hW7XwzZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def compare_models(self, image_source, model_names=['resnet50', 'vgg16', 'efficientnet_b0']):\n",
        "        \"\"\"ì—¬ëŸ¬ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ\"\"\"\n",
        "        print(f\"ğŸ”„ ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì‹œì‘...\")\n",
        "\n",
        "        original_model = self.model\n",
        "        original_name = original_model.__class__.__name__\n",
        "\n",
        "        results_comparison = []\n",
        "\n",
        "        for model_name in model_names:\n",
        "            print(f\"\\nğŸ§  {model_name} ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì¤‘...\")\n",
        "\n",
        "            # ëª¨ë¸ ë³€ê²½\n",
        "            self.model = self.load_model(model_name)\n",
        "            self.model.eval()\n",
        "\n",
        "            # ì˜ˆì¸¡\n",
        "            result = self.predict(image_source, top_k=3)\n",
        "            if result:\n",
        "                best_pred = result['predictions'][0]\n",
        "                results_comparison.append({\n",
        "                    'model_name': model_name,\n",
        "                    'best_class': best_pred['class_name'],\n",
        "                    'confidence': best_pred['percentage'],\n",
        "                    'top3': result['predictions']\n",
        "                })\n",
        "\n",
        "        # ì›ë˜ ëª¨ë¸ ë³µì›\n",
        "        self.model = original_model\n",
        "\n",
        "        # ë¹„êµ ê²°ê³¼ ì‹œê°í™”\n",
        "        if results_comparison:\n",
        "            self.visualize_model_comparison(results_comparison, image_source)\n",
        "\n",
        "        return results_comparison\n"
      ],
      "metadata": {
        "id": "JMlQv-n1n7z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `compare_models(self, image_source, model_names=['resnet50', 'vgg16', 'efficientnet_b0'])` method(ë©”ì„œë“œ)ëŠ” multiple models(ì—¬ëŸ¬ ëª¨ë¸)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def compare_models(self, image_source, model_names=['resnet50', 'vgg16', 'efficientnet_b0']):\n",
        "   ```\n",
        "   - `image_source`: ë¹„êµí•  ì´ë¯¸ì§€ ì†ŒìŠ¤\n",
        "   - `model_names`: ë¹„êµí•  model list(ëª¨ë¸ ë¦¬ìŠ¤íŠ¸), default(ê¸°ë³¸ê°’) 3ê°œ ëª¨ë¸\n",
        "\n",
        "2. **Current model backup(í˜„ì¬ ëª¨ë¸ ë°±ì—…)**:\n",
        "   ```python\n",
        "   original_model = self.model\n",
        "   original_name = original_model.__class__.__name__\n",
        "   ```\n",
        "   - í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ model(ëª¨ë¸) ë°±ì—… ì €ì¥\n",
        "   - `__class__.__name__`: class name(í´ë˜ìŠ¤ ì´ë¦„) ì¶”ì¶œ\n",
        "\n",
        "3. **Results container(ê²°ê³¼ ì»¨í…Œì´ë„ˆ)**:\n",
        "   ```python\n",
        "   results_comparison = []\n",
        "   ```\n",
        "   - ê° model(ëª¨ë¸)ì˜ ê²°ê³¼ë¥¼ ì €ì¥í•  empty list(ë¹ˆ ë¦¬ìŠ¤íŠ¸)\n",
        "\n",
        "4. **Model iteration(ëª¨ë¸ ë°˜ë³µ)**:\n",
        "   ```python\n",
        "   for model_name in model_names:\n",
        "       print(f\"\\nğŸ§  {model_name} ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì¤‘...\")\n",
        "   ```\n",
        "   - ê° model(ëª¨ë¸)ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬\n",
        "\n",
        "5. **Model switching(ëª¨ë¸ êµì²´)**:\n",
        "   ```python\n",
        "   self.model = self.load_model(model_name)\n",
        "   self.model.eval()\n",
        "   ```\n",
        "   - `load_model()`: ìƒˆë¡œìš´ model(ëª¨ë¸) ë¡œë”©\n",
        "   - `eval()`: evaluation mode(í‰ê°€ ëª¨ë“œ) ì„¤ì •\n",
        "\n",
        "6. **Prediction execution(ì˜ˆì¸¡ ì‹¤í–‰)**:\n",
        "   ```python\n",
        "   result = self.predict(image_source, top_k=3)\n",
        "   if result:\n",
        "       best_pred = result['predictions'][0]\n",
        "   ```\n",
        "   - `predict()`: ê° model(ëª¨ë¸)ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "   - `top_k=3`: ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ì¶”ì¶œ\n",
        "   - `best_pred`: ìµœê³  confidence(ì‹ ë¢°ë„) ê²°ê³¼\n",
        "\n",
        "7. **Results aggregation(ê²°ê³¼ ì§‘ê³„)**:\n",
        "   ```python\n",
        "   results_comparison.append({\n",
        "       'model_name': model_name,\n",
        "       'best_class': best_pred['class_name'],\n",
        "       'confidence': best_pred['percentage'],\n",
        "       'top3': result['predictions']\n",
        "   })\n",
        "   ```\n",
        "   - ê° model(ëª¨ë¸)ì˜ ê²°ê³¼ë¥¼ dictionary(ë”•ì…”ë„ˆë¦¬) í˜•íƒœë¡œ ì €ì¥\n",
        "   - `best_class`: ìµœê³  ì˜ˆì¸¡ class(í´ë˜ìŠ¤)\n",
        "   - `confidence`: ì‹ ë¢°ë„ percentage(í¼ì„¼íŠ¸)\n",
        "   - `top3`: ìƒìœ„ 3ê°œ ì „ì²´ ê²°ê³¼\n",
        "\n",
        "8. **Model restoration(ëª¨ë¸ ë³µì›)**:\n",
        "   ```python\n",
        "   self.model = original_model\n",
        "   ```\n",
        "   - ì›ë˜ ì‚¬ìš©í•˜ë˜ model(ëª¨ë¸)ë¡œ ë³µì›\n",
        "   - state preservation(ìƒíƒœ ë³´ì¡´)\n",
        "\n",
        "9. **Visualization call(ì‹œê°í™” í˜¸ì¶œ)**:\n",
        "   ```python\n",
        "   if results_comparison:\n",
        "       self.visualize_model_comparison(results_comparison, image_source)\n",
        "   ```\n",
        "   - ê²°ê³¼ê°€ ìˆìœ¼ë©´ visualization method(ì‹œê°í™” ë©”ì„œë“œ) í˜¸ì¶œ\n",
        "\n",
        "10. **Return value(ë°˜í™˜ê°’)**:\n",
        "    ```python\n",
        "    return results_comparison\n",
        "    ```\n",
        "    - ëª¨ë“  model(ëª¨ë¸)ì˜ ë¹„êµ ê²°ê³¼ ë°˜í™˜\n",
        "\n",
        "**Method workflow(ë©”ì„œë“œ ì›Œí¬í”Œë¡œìš°):**\n",
        "1. í˜„ì¬ model(ëª¨ë¸) ë°±ì—…\n",
        "2. ê° model(ëª¨ë¸)ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ:\n",
        "   - Model loading(ëª¨ë¸ ë¡œë”©)\n",
        "   - Prediction execution(ì˜ˆì¸¡ ì‹¤í–‰)\n",
        "   - Results storage(ê²°ê³¼ ì €ì¥)\n",
        "3. ì›ë˜ model(ëª¨ë¸) ë³µì›\n",
        "4. ê²°ê³¼ ì‹œê°í™”\n",
        "5. ë¹„êµ ê²°ê³¼ ë°˜í™˜\n",
        "\n",
        "**Data structure(ë°ì´í„° êµ¬ì¡°):**\n",
        "- `results_comparison`: list of dictionaries(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)\n",
        "- ê° dictionary(ë”•ì…”ë„ˆë¦¬): model name, best prediction, confidence, top-3 results í¬í•¨"
      ],
      "metadata": {
        "id": "G-0L_I4Zw7AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    def visualize_model_comparison(self, results_comparison, image_source):\n",
        "        \"\"\"ëª¨ë¸ ë¹„êµ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
        "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
        "        image = self.load_image(image_source)\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # ì›ë³¸ ì´ë¯¸ì§€\n",
        "        axes[0, 0].imshow(image)\n",
        "        axes[0, 0].set_title('Original Image', fontsize=14, fontweight='bold')\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        # ê° ëª¨ë¸ë³„ Top 1 ê²°ê³¼\n",
        "        model_names = [result['model_name'] for result in results_comparison]\n",
        "        confidences = [result['confidence'] for result in results_comparison]\n",
        "        predictions = [result['best_class'][:15] for result in results_comparison]  # ì´ë¦„ ë‹¨ì¶•\n",
        "\n",
        "        colors = ['red', 'blue', 'green', 'orange', 'purple'][:len(model_names)]\n",
        "\n",
        "        bars = axes[0, 1].bar(model_names, confidences, color=colors, alpha=0.7)\n",
        "        axes[0, 1].set_title('Model Confidence Comparison', fontsize=14, fontweight='bold')\n",
        "        axes[0, 1].set_ylabel('Confidence (%)')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "        # ë§‰ëŒ€ì— ì˜ˆì¸¡ í´ë˜ìŠ¤ì™€ í™•ë¥  í‘œì‹œ\n",
        "        for bar, pred, conf in zip(bars, predictions, confidences):\n",
        "            axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "                           f'{pred}\\n{conf:.1f}%', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        # ìƒì„¸ ë¹„êµ í…Œì´ë¸”\n",
        "        axes[1, 0].axis('off')\n",
        "        table_data = []\n",
        "        for result in results_comparison:\n",
        "            row = [result['model_name'], result['best_class'][:20], f\"{result['confidence']:.1f}%\"]\n",
        "            table_data.append(row)\n",
        "\n",
        "        table = axes[1, 0].table(cellText=table_data,\n",
        "                                colLabels=['Model', 'Best Prediction', 'Confidence'],\n",
        "                                cellLoc='center',\n",
        "                                loc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 1.5)\n",
        "        axes[1, 0].set_title('Detailed Comparison', fontsize=14, fontweight='bold')\n",
        "\n",
        "        # ëª¨ë¸ë³„ Top 3 ë¹„êµ\n",
        "        axes[1, 1].axis('off')\n",
        "        y_pos = 0.9\n",
        "        for result in results_comparison:\n",
        "            axes[1, 1].text(0.05, y_pos, f\"ğŸ§  {result['model_name']}:\", fontweight='bold', fontsize=12)\n",
        "            y_pos -= 0.08\n",
        "            for i, pred in enumerate(result['top3']):\n",
        "                axes[1, 1].text(0.1, y_pos, f\"{i+1}. {pred['class_name'][:25]} ({pred['percentage']:.1f}%)\",\n",
        "                               fontsize=10)\n",
        "                y_pos -= 0.06\n",
        "            y_pos -= 0.02\n",
        "\n",
        "        axes[1, 1].set_xlim(0, 1)\n",
        "        axes[1, 1].set_ylim(0, 1)\n",
        "        axes[1, 1].set_title('Top 3 Predictions per Model', fontsize=14, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "I8iRER-SoVkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ë„¤, ì´í•´í–ˆìŠµë‹ˆë‹¤. ì•ìœ¼ë¡œ ì´ëŸ° í˜•ì‹ìœ¼ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì´ `compare_models()` (ëª¨ë¸ ë¹„êµ) method(ë©”ì„œë“œ)ëŠ” multiple models(ì—¬ëŸ¬ ëª¨ë¸)ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Method signature(ë©”ì„œë“œ ì„œëª…)**:\n",
        "   ```python\n",
        "   def compare_models(self, image_source, model_names=['resnet50', 'vgg16', 'efficientnet_b0']):\n",
        "   ```\n",
        "   - `image_source` (ì´ë¯¸ì§€ ì†ŒìŠ¤): ë¹„êµí•  ì´ë¯¸ì§€ ì†ŒìŠ¤\n",
        "   - `model_names` (ëª¨ë¸ ì´ë¦„ë“¤): ë¹„êµí•  model list(ëª¨ë¸ ë¦¬ìŠ¤íŠ¸), default(ê¸°ë³¸ê°’) 3ê°œ ëª¨ë¸\n",
        "\n",
        "2. **Current model backup(í˜„ì¬ ëª¨ë¸ ë°±ì—…)**:\n",
        "   ```python\n",
        "   original_model = self.model\n",
        "   original_name = original_model.__class__.__name__\n",
        "   ```\n",
        "   - í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ model(ëª¨ë¸) ë°±ì—… ì €ì¥\n",
        "   - `__class__.__name__`: class name(í´ë˜ìŠ¤ ì´ë¦„) ì¶”ì¶œ\n",
        "\n",
        "3. **Results container(ê²°ê³¼ ì»¨í…Œì´ë„ˆ)**:\n",
        "   ```python\n",
        "   results_comparison = []\n",
        "   ```\n",
        "   - ê° model(ëª¨ë¸)ì˜ ê²°ê³¼ë¥¼ ì €ì¥í•  empty list(ë¹ˆ ë¦¬ìŠ¤íŠ¸)\n",
        "\n",
        "4. **Model iteration(ëª¨ë¸ ë°˜ë³µ)**:\n",
        "   ```python\n",
        "   for model_name in model_names:\n",
        "       print(f\"\\nğŸ§  {model_name} ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì¤‘...\")\n",
        "   ```\n",
        "   - ê° model(ëª¨ë¸)ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬\n",
        "\n",
        "5. **Model switching(ëª¨ë¸ êµì²´)**:\n",
        "   ```python\n",
        "   self.model = self.load_model(model_name)\n",
        "   self.model.eval()\n",
        "   ```\n",
        "   - `load_model()` (ëª¨ë¸ ë¡œë“œ): ìƒˆë¡œìš´ model(ëª¨ë¸) ë¡œë”©\n",
        "   - `eval()` (í‰ê°€ ëª¨ë“œ): evaluation mode(í‰ê°€ ëª¨ë“œ) ì„¤ì •\n",
        "\n",
        "6. **Prediction execution(ì˜ˆì¸¡ ì‹¤í–‰)**:\n",
        "   ```python\n",
        "   result = self.predict(image_source, top_k=3)\n",
        "   if result:\n",
        "       best_pred = result['predictions'][0]\n",
        "   ```\n",
        "   - `predict()` (ì˜ˆì¸¡): ê° model(ëª¨ë¸)ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
        "   - `top_k=3`: ìƒìœ„ 3ê°œ ê²°ê³¼ë§Œ ì¶”ì¶œ\n",
        "   - `best_pred` (ìµœê³  ì˜ˆì¸¡): ìµœê³  confidence(ì‹ ë¢°ë„) ê²°ê³¼\n",
        "\n",
        "7. **Results aggregation(ê²°ê³¼ ì§‘ê³„)**:\n",
        "   ```python\n",
        "   results_comparison.append({\n",
        "       'model_name': model_name,\n",
        "       'best_class': best_pred['class_name'],\n",
        "       'confidence': best_pred['percentage'],\n",
        "       'top3': result['predictions']\n",
        "   })\n",
        "   ```\n",
        "   - ê° model(ëª¨ë¸)ì˜ ê²°ê³¼ë¥¼ dictionary(ë”•ì…”ë„ˆë¦¬) í˜•íƒœë¡œ ì €ì¥\n",
        "   - `best_class` (ìµœê³  í´ë˜ìŠ¤): ìµœê³  ì˜ˆì¸¡ class(í´ë˜ìŠ¤)\n",
        "   - `confidence` (ì‹ ë¢°ë„): ì‹ ë¢°ë„ percentage(í¼ì„¼íŠ¸)\n",
        "   - `top3` (ìƒìœ„ 3ê°œ): ìƒìœ„ 3ê°œ ì „ì²´ ê²°ê³¼\n",
        "\n",
        "8. **Model restoration(ëª¨ë¸ ë³µì›)**:\n",
        "   ```python\n",
        "   self.model = original_model\n",
        "   ```\n",
        "   - ì›ë˜ ì‚¬ìš©í•˜ë˜ model(ëª¨ë¸)ë¡œ ë³µì›\n",
        "   - state preservation(ìƒíƒœ ë³´ì¡´)\n",
        "\n",
        "9. **Visualization call(ì‹œê°í™” í˜¸ì¶œ)**:\n",
        "   ```python\n",
        "   if results_comparison:\n",
        "       self.visualize_model_comparison(results_comparison, image_source)\n",
        "   ```\n",
        "   - ê²°ê³¼ê°€ ìˆìœ¼ë©´ visualization method(ì‹œê°í™” ë©”ì„œë“œ) í˜¸ì¶œ\n",
        "\n",
        "10. **Return value(ë°˜í™˜ê°’)**:\n",
        "    ```python\n",
        "    return results_comparison\n",
        "    ```\n",
        "    - ëª¨ë“  model(ëª¨ë¸)ì˜ ë¹„êµ ê²°ê³¼ ë°˜í™˜\n",
        "\n",
        "**Method workflow(ë©”ì„œë“œ ì›Œí¬í”Œë¡œìš°):**\n",
        "1. í˜„ì¬ model(ëª¨ë¸) ë°±ì—…\n",
        "2. ê° model(ëª¨ë¸)ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ:\n",
        "   - Model loading(ëª¨ë¸ ë¡œë”©)\n",
        "   - Prediction execution(ì˜ˆì¸¡ ì‹¤í–‰)\n",
        "   - Results storage(ê²°ê³¼ ì €ì¥)\n",
        "3. ì›ë˜ model(ëª¨ë¸) ë³µì›\n",
        "4. ê²°ê³¼ ì‹œê°í™”\n",
        "5. ë¹„êµ ê²°ê³¼ ë°˜í™˜\n",
        "\n",
        "**Data structure(ë°ì´í„° êµ¬ì¡°):**\n",
        "- `results_comparison`: list of dictionaries(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸)\n",
        "- ê° dictionary(ë”•ì…”ë„ˆë¦¬): model name, best prediction, confidence, top-3 results í¬í•¨"
      ],
      "metadata": {
        "id": "QVW2zZjlxhGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ì‹¤í–‰ í•¨ìˆ˜ë“¤\n",
        "# ============================================================================="
      ],
      "metadata": {
        "id": "i0VreJ0ioVil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_uploaded_image():\n",
        "    \"\"\"íŒŒì¼ ì—…ë¡œë“œ í›„ ImageNet ë¶„ë¥˜\"\"\"\n",
        "    print(\"ğŸš€ ImageNet 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ê¸° ì‹œì‘!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # íŒŒì¼ ì—…ë¡œë“œ\n",
        "    print(\"ğŸ“ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”...\")\n",
        "    print(\"ğŸ¯ 1000ê°œ í´ë˜ìŠ¤ ì¤‘ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ê°ì²´ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤!\")\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "        return None\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"ğŸ“· ì—…ë¡œë“œëœ íŒŒì¼: {filename}\")\n",
        "\n",
        "    try:\n",
        "        # ë¶„ë¥˜ê¸° ìƒì„±\n",
        "        classifier = ImageNetClassifier(model_name='resnet50')\n",
        "\n",
        "        # ì˜ˆì¸¡\n",
        "        results = classifier.predict(filename, top_k=10)\n",
        "\n",
        "        # ê²°ê³¼ ì‹œê°í™”\n",
        "        classifier.visualize_results(results, show_top_k=5)\n",
        "\n",
        "        print(\"\\nâœ… ImageNet ë¶„ë¥˜ ì™„ë£Œ!\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "vZImnFnooVgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `classify_uploaded_image()` (ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë¶„ë¥˜) function(í•¨ìˆ˜)ëŠ” **Google Colabì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ImageNet ë¶„ë¥˜ë¥¼ ìˆ˜í–‰**í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Function signature(í•¨ìˆ˜ ì„œëª…)**:\n",
        "   ```python\n",
        "   def classify_uploaded_image():\n",
        "   ```\n",
        "   - parameter(ë§¤ê°œë³€ìˆ˜) ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” standalone function(ë…ë¦½ í•¨ìˆ˜)\n",
        "\n",
        "2. **Interface initialization(ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”)**:\n",
        "   ```python\n",
        "   print(\"ğŸš€ ImageNet 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ê¸° ì‹œì‘!\")\n",
        "   print(\"=\" * 60)\n",
        "   ```\n",
        "   - user interface(ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤) ì‹œì‘ ë©”ì‹œì§€ ì¶œë ¥\n",
        "   - visual separator(ì‹œê°ì  êµ¬ë¶„ì„ ) ìƒì„±\n",
        "\n",
        "3. **File upload prompt(íŒŒì¼ ì—…ë¡œë“œ ì•ˆë‚´)**:\n",
        "   ```python\n",
        "   print(\"ğŸ“ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”...\")\n",
        "   print(\"ğŸ¯ 1000ê°œ í´ë˜ìŠ¤ ì¤‘ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ê°ì²´ë¥¼ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤!\")\n",
        "   ```\n",
        "   - user instruction(ì‚¬ìš©ì ì§€ì‹œì‚¬í•­) ì¶œë ¥\n",
        "   - ImageNet 1000 classes(í´ë˜ìŠ¤) ì„¤ëª…\n",
        "\n",
        "4. **Google Colab file upload(êµ¬ê¸€ ì½œë© íŒŒì¼ ì—…ë¡œë“œ)**:\n",
        "   ```python\n",
        "   from google.colab import files\n",
        "   uploaded = files.upload()\n",
        "   ```\n",
        "   - `files.upload()` (íŒŒì¼ ì—…ë¡œë“œ): Colabì˜ file upload widget(íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯) í˜¸ì¶œ\n",
        "   - `uploaded` (ì—…ë¡œë“œëœ íŒŒì¼): dictionary format(ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)ì˜ uploaded files(ì—…ë¡œë“œëœ íŒŒì¼ë“¤)\n",
        "\n",
        "5. **Upload validation(ì—…ë¡œë“œ ê²€ì¦)**:\n",
        "   ```python\n",
        "   if not uploaded:\n",
        "       print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "       return None\n",
        "   ```\n",
        "   - empty upload(ë¹ˆ ì—…ë¡œë“œ) í™•ì¸\n",
        "   - error handling(ì˜¤ë¥˜ ì²˜ë¦¬)ìœ¼ë¡œ early return(ì¡°ê¸° ë°˜í™˜)\n",
        "\n",
        "6. **Filename extraction(íŒŒì¼ëª… ì¶”ì¶œ)**:\n",
        "   ```python\n",
        "   filename = list(uploaded.keys())[0]\n",
        "   print(f\"ğŸ“· ì—…ë¡œë“œëœ íŒŒì¼: {filename}\")\n",
        "   ```\n",
        "   - `uploaded.keys()`: uploaded dictionary(ì—…ë¡œë“œëœ ë”•ì…”ë„ˆë¦¬)ì˜ keys(í‚¤ë“¤) ì¶”ì¶œ\n",
        "   - ì²« ë²ˆì§¸ file(íŒŒì¼)ì˜ name(ì´ë¦„) ì„ íƒ\n",
        "\n",
        "7. **Classification workflow(ë¶„ë¥˜ ì›Œí¬í”Œë¡œìš°)**:\n",
        "   ```python\n",
        "   try:\n",
        "       # ë¶„ë¥˜ê¸° ìƒì„±\n",
        "       classifier = ImageNetClassifier(model_name='resnet50')\n",
        "       \n",
        "       # ì˜ˆì¸¡\n",
        "       results = classifier.predict(filename, top_k=10)\n",
        "       \n",
        "       # ê²°ê³¼ ì‹œê°í™”\n",
        "       classifier.visualize_results(results, show_top_k=5)\n",
        "   ```\n",
        "   - `ImageNetClassifier()` (ImageNet ë¶„ë¥˜ê¸°): ResNet-50 model(ëª¨ë¸)ë¡œ classifier instance(ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤) ìƒì„±\n",
        "   - `predict()` (ì˜ˆì¸¡): `top_k=10`ìœ¼ë¡œ ìƒìœ„ 10ê°œ ê²°ê³¼ ì˜ˆì¸¡\n",
        "   - `visualize_results()` (ê²°ê³¼ ì‹œê°í™”): ìƒìœ„ 5ê°œ ê²°ê³¼ë§Œ ì‹œê°í™”\n",
        "\n",
        "8. **Success message(ì„±ê³µ ë©”ì‹œì§€)**:\n",
        "   ```python\n",
        "   print(\"\\nâœ… ImageNet ë¶„ë¥˜ ì™„ë£Œ!\")\n",
        "   return results\n",
        "   ```\n",
        "   - completion message(ì™„ë£Œ ë©”ì‹œì§€) ì¶œë ¥\n",
        "   - prediction results(ì˜ˆì¸¡ ê²°ê³¼) ë°˜í™˜\n",
        "\n",
        "9. **Exception handling(ì˜ˆì™¸ ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   except Exception as e:\n",
        "       print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "       return None\n",
        "   ```\n",
        "   - generic exception(ì¼ë°˜ ì˜ˆì™¸) ì²˜ë¦¬\n",
        "   - error message(ì˜¤ë¥˜ ë©”ì‹œì§€) ì¶œë ¥ í›„ `None` ë°˜í™˜\n",
        "\n",
        "**Function workflow(í•¨ìˆ˜ ì›Œí¬í”Œë¡œìš°):**\n",
        "1. User interface(ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤) ì´ˆê¸°í™”\n",
        "2. File upload(íŒŒì¼ ì—…ë¡œë“œ) ì‹¤í–‰\n",
        "3. Upload validation(ì—…ë¡œë“œ ê²€ì¦)\n",
        "4. Filename extraction(íŒŒì¼ëª… ì¶”ì¶œ)\n",
        "5. Classifier initialization(ë¶„ë¥˜ê¸° ì´ˆê¸°í™”)\n",
        "6. Image prediction(ì´ë¯¸ì§€ ì˜ˆì¸¡)\n",
        "7. Results visualization(ê²°ê³¼ ì‹œê°í™”)\n",
        "8. Success/error handling(ì„±ê³µ/ì˜¤ë¥˜ ì²˜ë¦¬)\n",
        "\n",
        "**Key features(ì£¼ìš” íŠ¹ì§•):**\n",
        "- **Google Colab integration(êµ¬ê¸€ ì½œë© í†µí•©)**: Colab environment(ì½œë© í™˜ê²½)ì— ìµœì í™”\n",
        "- **Interactive workflow(ëŒ€í™”í˜• ì›Œí¬í”Œë¡œìš°)**: ë‹¨ê³„ë³„ ì‚¬ìš©ì ì•ˆë‚´\n",
        "- **Error handling(ì˜¤ë¥˜ ì²˜ë¦¬)**: robust exception handling(ê²¬ê³ í•œ ì˜ˆì™¸ ì²˜ë¦¬)\n",
        "- **Visual feedback(ì‹œê°ì  í”¼ë“œë°±)**: ì´ëª¨ì§€ì™€ formatting(ì„œì‹)ì„ í†µí•œ ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ\n",
        "\n",
        "**Return value(ë°˜í™˜ê°’):**\n",
        "- Success case(ì„±ê³µ ì‹œ): prediction results dictionary(ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬)\n",
        "- Failure case(ì‹¤íŒ¨ ì‹œ): `None`"
      ],
      "metadata": {
        "id": "xCLeGTxMxkUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_multiple_models():\n",
        "    \"\"\"ì—¬ëŸ¬ ëª¨ë¸ë¡œ ë™ì¼ ì´ë¯¸ì§€ ë¹„êµ\"\"\"\n",
        "    print(\"ğŸ”„ ë‹¤ì¤‘ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "        return None\n",
        "\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    print(f\"ğŸ“· ì—…ë¡œë“œëœ íŒŒì¼: {filename}\")\n",
        "\n",
        "    try:\n",
        "        # ë¶„ë¥˜ê¸° ìƒì„±\n",
        "        classifier = ImageNetClassifier()\n",
        "\n",
        "        # ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ\n",
        "        models_to_compare = ['resnet50', 'vgg16', 'efficientnet_b0', 'mobilenet_v2']\n",
        "        comparison_results = classifier.compare_models(filename, models_to_compare)\n",
        "\n",
        "        print(\"\\nâœ… ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì™„ë£Œ!\")\n",
        "        return comparison_results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "xjxz1sDToVdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `compare_multiple_models()` (ì—¬ëŸ¬ ëª¨ë¸ ë¹„êµ) function(í•¨ìˆ˜)ëŠ” **ë™ì¼í•œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì—¬ëŸ¬ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµ**í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Function signature(í•¨ìˆ˜ ì„œëª…)**:\n",
        "   ```python\n",
        "   def compare_multiple_models():\n",
        "   ```\n",
        "   - parameter(ë§¤ê°œë³€ìˆ˜) ì—†ëŠ” standalone function(ë…ë¦½ í•¨ìˆ˜)\n",
        "   - multi-model comparison(ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ) ì „ìš©\n",
        "\n",
        "2. **Interface initialization(ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”)**:\n",
        "   ```python\n",
        "   print(\"ğŸ”„ ë‹¤ì¤‘ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ!\")\n",
        "   print(\"=\" * 60)\n",
        "   ```\n",
        "   - comparison workflow(ë¹„êµ ì›Œí¬í”Œë¡œìš°) ì‹œì‘ ë©”ì‹œì§€\n",
        "   - visual separator(ì‹œê°ì  êµ¬ë¶„ì„ ) ìƒì„±\n",
        "\n",
        "3. **File upload process(íŒŒì¼ ì—…ë¡œë“œ ê³¼ì •)**:\n",
        "   ```python\n",
        "   from google.colab import files\n",
        "   uploaded = files.upload()\n",
        "   ```\n",
        "   - `files.upload()` (íŒŒì¼ ì—…ë¡œë“œ): Colab file upload widget(ì½œë© íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯) í˜¸ì¶œ\n",
        "   - `uploaded` (ì—…ë¡œë“œëœ íŒŒì¼): uploaded files dictionary(ì—…ë¡œë“œëœ íŒŒì¼ ë”•ì…”ë„ˆë¦¬)\n",
        "\n",
        "4. **Upload validation(ì—…ë¡œë“œ ê²€ì¦)**:\n",
        "   ```python\n",
        "   if not uploaded:\n",
        "       print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "       return None\n",
        "   ```\n",
        "   - empty upload check(ë¹ˆ ì—…ë¡œë“œ í™•ì¸)\n",
        "   - early termination(ì¡°ê¸° ì¢…ë£Œ) with error message(ì˜¤ë¥˜ ë©”ì‹œì§€)\n",
        "\n",
        "5. **Filename extraction(íŒŒì¼ëª… ì¶”ì¶œ)**:\n",
        "   ```python\n",
        "   filename = list(uploaded.keys())[0]\n",
        "   print(f\"ğŸ“· ì—…ë¡œë“œëœ íŒŒì¼: {filename}\")\n",
        "   ```\n",
        "   - `uploaded.keys()[0]`: ì²« ë²ˆì§¸ uploaded file(ì—…ë¡œë“œëœ íŒŒì¼)ì˜ name(ì´ë¦„) ì¶”ì¶œ\n",
        "   - confirmation message(í™•ì¸ ë©”ì‹œì§€) ì¶œë ¥\n",
        "\n",
        "6. **Classifier initialization(ë¶„ë¥˜ê¸° ì´ˆê¸°í™”)**:\n",
        "   ```python\n",
        "   classifier = ImageNetClassifier()\n",
        "   ```\n",
        "   - `ImageNetClassifier()` (ImageNet ë¶„ë¥˜ê¸°): default model(ê¸°ë³¸ ëª¨ë¸)ë¡œ classifier instance(ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤) ìƒì„±\n",
        "   - ë‚´ë¶€ì—ì„œ model switching(ëª¨ë¸ êµì²´) ìˆ˜í–‰\n",
        "\n",
        "7. **Model comparison setup(ëª¨ë¸ ë¹„êµ ì„¤ì •)**:\n",
        "   ```python\n",
        "   models_to_compare = ['resnet50', 'vgg16', 'efficientnet_b0', 'mobilenet_v2']\n",
        "   ```\n",
        "   - `models_to_compare` (ë¹„êµí•  ëª¨ë¸ë“¤): 4ê°œì˜ different architectures(ë‹¤ë¥¸ ì•„í‚¤í…ì²˜) ì •ì˜\n",
        "   - ResNet-50, VGG-16, EfficientNet-B0, MobileNet-V2 í¬í•¨\n",
        "\n",
        "8. **Model comparison execution(ëª¨ë¸ ë¹„êµ ì‹¤í–‰)**:\n",
        "   ```python\n",
        "   comparison_results = classifier.compare_models(filename, models_to_compare)\n",
        "   ```\n",
        "   - `compare_models()` (ëª¨ë¸ ë¹„êµ): ê° model(ëª¨ë¸)ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ prediction(ì˜ˆì¸¡) ìˆ˜í–‰\n",
        "   - `comparison_results` (ë¹„êµ ê²°ê³¼): ëª¨ë“  model results(ëª¨ë¸ ê²°ê³¼)ë¥¼ ë‹´ì€ list(ë¦¬ìŠ¤íŠ¸)\n",
        "\n",
        "9. **Success completion(ì„±ê³µ ì™„ë£Œ)**:\n",
        "   ```python\n",
        "   print(\"\\nâœ… ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì™„ë£Œ!\")\n",
        "   return comparison_results\n",
        "   ```\n",
        "   - completion message(ì™„ë£Œ ë©”ì‹œì§€) ì¶œë ¥\n",
        "   - comprehensive comparison results(ì¢…í•© ë¹„êµ ê²°ê³¼) ë°˜í™˜\n",
        "\n",
        "10. **Exception handling(ì˜ˆì™¸ ì²˜ë¦¬)**:\n",
        "    ```python\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return None\n",
        "    ```\n",
        "    - generic error handling(ì¼ë°˜ ì˜¤ë¥˜ ì²˜ë¦¬)\n",
        "    - error message(ì˜¤ë¥˜ ë©”ì‹œì§€) ì¶œë ¥ í›„ `None` ë°˜í™˜\n",
        "\n",
        "**Function workflow(í•¨ìˆ˜ ì›Œí¬í”Œë¡œìš°):**\n",
        "1. User interface(ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤) ì´ˆê¸°í™”\n",
        "2. File upload(íŒŒì¼ ì—…ë¡œë“œ) ì‹¤í–‰\n",
        "3. Upload validation(ì—…ë¡œë“œ ê²€ì¦)\n",
        "4. Filename extraction(íŒŒì¼ëª… ì¶”ì¶œ)\n",
        "5. Classifier initialization(ë¶„ë¥˜ê¸° ì´ˆê¸°í™”)\n",
        "6. Model list(ëª¨ë¸ ë¦¬ìŠ¤íŠ¸) ì •ì˜\n",
        "7. Multi-model comparison(ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ) ì‹¤í–‰\n",
        "8. Results compilation(ê²°ê³¼ ì§‘ê³„)\n",
        "9. Success/error handling(ì„±ê³µ/ì˜¤ë¥˜ ì²˜ë¦¬)\n",
        "\n",
        "**Key differences from single model(ë‹¨ì¼ ëª¨ë¸ê³¼ì˜ ì£¼ìš” ì°¨ì´ì ):**\n",
        "- **Multiple architectures(ë‹¤ì¤‘ ì•„í‚¤í…ì²˜)**: 4ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ model types(ëª¨ë¸ ìœ í˜•)\n",
        "- **Performance comparison(ì„±ëŠ¥ ë¹„êµ)**: confidence scores(ì‹ ë¢°ë„ ì ìˆ˜) ë¹„êµ\n",
        "- **Comprehensive visualization(ì¢…í•© ì‹œê°í™”)**: ëª¨ë“  ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ í•œ í™”ë©´ì— í‘œì‹œ\n",
        "\n",
        "**Model architectures compared(ë¹„êµë˜ëŠ” ëª¨ë¸ ì•„í‚¤í…ì²˜):**\n",
        "- `resnet50`: Residual Network(ì”ì°¨ ë„¤íŠ¸ì›Œí¬) - 50 layers(ì¸µ)\n",
        "- `vgg16`: Visual Geometry Group(ë¹„ì£¼ì–¼ ì§€ì˜¤ë©”íŠ¸ë¦¬ ê·¸ë£¹) - 16 layers(ì¸µ)\n",
        "- `efficientnet_b0`: Efficient Neural Network(íš¨ìœ¨ì  ì‹ ê²½ë§) - Base model(ê¸°ë³¸ ëª¨ë¸)\n",
        "- `mobilenet_v2`: Mobile Network(ëª¨ë°”ì¼ ë„¤íŠ¸ì›Œí¬) - Version 2(ë²„ì „ 2)\n",
        "\n",
        "**Return value(ë°˜í™˜ê°’):**\n",
        "- Success case(ì„±ê³µ ì‹œ): list of dictionaries(ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸) containing model comparison results(ëª¨ë¸ ë¹„êµ ê²°ê³¼)\n",
        "- Failure case(ì‹¤íŒ¨ ì‹œ): `None`"
      ],
      "metadata": {
        "id": "M1ZpwmQ-xktc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_classify():\n",
        "    \"\"\"ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ì—…ë¡œë“œ ë¶„ë¥˜\"\"\"\n",
        "    print(\"ğŸ“ ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ë¶„ë¥˜!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        classifier = ImageNetClassifier()\n",
        "        results_list = []\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            print(f\"\\nğŸ” {filename} ë¶„ì„ ì¤‘...\")\n",
        "            results = classifier.predict(filename, top_k=5)\n",
        "\n",
        "            if results:\n",
        "                # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥\n",
        "                best_pred = results['predictions'][0]\n",
        "                print(f\"ğŸ† {filename}: {best_pred['class_name']} ({best_pred['percentage']:.1f}%)\")\n",
        "                results_list.append((filename, best_pred['class_name'], best_pred['percentage']))\n",
        "\n",
        "        # ì „ì²´ ê²°ê³¼ ìš”ì•½\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"ğŸ“‹ ì¼ê´„ ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½\")\n",
        "        print(f\"{'='*60}\")\n",
        "        for filename, pred_class, confidence in results_list:\n",
        "            print(f\"ğŸ“· {filename:25} â†’ {pred_class:20} ({confidence:.1f}%)\")\n",
        "\n",
        "        return results_list\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "kyBxkOQpoVXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ `batch_classify()` (ì¼ê´„ ë¶„ë¥˜) function(í•¨ìˆ˜)ëŠ” **ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ì—¬ ì¼ê´„ì ìœ¼ë¡œ ë¶„ë¥˜**í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì½”ë“œ ë¶„ì„:**\n",
        "\n",
        "1. **Function signature(í•¨ìˆ˜ ì„œëª…)**:\n",
        "   ```python\n",
        "   def batch_classify():\n",
        "   ```\n",
        "   - parameter(ë§¤ê°œë³€ìˆ˜) ì—†ëŠ” standalone function(ë…ë¦½ í•¨ìˆ˜)\n",
        "   - batch processing(ì¼ê´„ ì²˜ë¦¬) ì „ìš©\n",
        "\n",
        "2. **Interface initialization(ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”)**:\n",
        "   ```python\n",
        "   print(\"ğŸ“ ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ë¶„ë¥˜!\")\n",
        "   print(\"=\" * 60)\n",
        "   ```\n",
        "   - batch classification(ì¼ê´„ ë¶„ë¥˜) ì‹œì‘ ë©”ì‹œì§€\n",
        "   - visual separator(ì‹œê°ì  êµ¬ë¶„ì„ ) ìƒì„±\n",
        "\n",
        "3. **Multiple file upload(ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ)**:\n",
        "   ```python\n",
        "   from google.colab import files\n",
        "   uploaded = files.upload()\n",
        "   ```\n",
        "   - `files.upload()` (íŒŒì¼ ì—…ë¡œë“œ): Colabì—ì„œ multiple files(ì—¬ëŸ¬ íŒŒì¼) ì—…ë¡œë“œ ì§€ì›\n",
        "   - `uploaded` (ì—…ë¡œë“œëœ íŒŒì¼ë“¤): filename-content dictionary(íŒŒì¼ëª…-ë‚´ìš© ë”•ì…”ë„ˆë¦¬)\n",
        "\n",
        "4. **Upload validation(ì—…ë¡œë“œ ê²€ì¦)**:\n",
        "   ```python\n",
        "   if not uploaded:\n",
        "       print(\"âŒ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
        "       return None\n",
        "   ```\n",
        "   - empty upload check(ë¹ˆ ì—…ë¡œë“œ í™•ì¸)\n",
        "   - early termination(ì¡°ê¸° ì¢…ë£Œ) with error handling(ì˜¤ë¥˜ ì²˜ë¦¬)\n",
        "\n",
        "5. **Batch processing setup(ì¼ê´„ ì²˜ë¦¬ ì„¤ì •)**:\n",
        "   ```python\n",
        "   classifier = ImageNetClassifier()\n",
        "   results_list = []\n",
        "   ```\n",
        "   - `ImageNetClassifier()` (ImageNet ë¶„ë¥˜ê¸°): single classifier instance(ë‹¨ì¼ ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤) ìƒì„±\n",
        "   - `results_list` (ê²°ê³¼ ë¦¬ìŠ¤íŠ¸): ëª¨ë“  image results(ì´ë¯¸ì§€ ê²°ê³¼)ë¥¼ ì €ì¥í•  container(ì»¨í…Œì´ë„ˆ)\n",
        "\n",
        "6. **File iteration loop(íŒŒì¼ ë°˜ë³µ ë£¨í”„)**:\n",
        "   ```python\n",
        "   for filename in uploaded.keys():\n",
        "       print(f\"\\nğŸ” {filename} ë¶„ì„ ì¤‘...\")\n",
        "       results = classifier.predict(filename, top_k=5)\n",
        "   ```\n",
        "   - `uploaded.keys()`: ì—…ë¡œë“œëœ ëª¨ë“  filenames(íŒŒì¼ëª…) ìˆœíšŒ\n",
        "   - `predict()` (ì˜ˆì¸¡): ê° image(ì´ë¯¸ì§€)ì— ëŒ€í•´ `top_k=5`ë¡œ ìƒìœ„ 5ê°œ ê²°ê³¼ ì˜ˆì¸¡\n",
        "   - progress indicator(ì§„í–‰ ìƒí™© í‘œì‹œ) ì¶œë ¥\n",
        "\n",
        "7. **Individual result processing(ê°œë³„ ê²°ê³¼ ì²˜ë¦¬)**:\n",
        "   ```python\n",
        "   if results:\n",
        "       best_pred = results['predictions'][0]\n",
        "       print(f\"ğŸ† {filename}: {best_pred['class_name']} ({best_pred['percentage']:.1f}%)\")\n",
        "       results_list.append((filename, best_pred['class_name'], best_pred['percentage']))\n",
        "   ```\n",
        "   - `best_pred` (ìµœê³  ì˜ˆì¸¡): ê°€ì¥ ë†’ì€ confidence(ì‹ ë¢°ë„)ë¥¼ ê°€ì§„ prediction(ì˜ˆì¸¡)\n",
        "   - immediate feedback(ì¦‰ì‹œ í”¼ë“œë°±): ê° image(ì´ë¯¸ì§€)ì˜ ê²°ê³¼ ì¦‰ì‹œ ì¶œë ¥\n",
        "   - `results_list.append()`: tuple format(íŠœí”Œ í˜•ì‹)ìœ¼ë¡œ ê²°ê³¼ ì €ì¥\n",
        "\n",
        "8. **Summary report generation(ìš”ì•½ ë³´ê³ ì„œ ìƒì„±)**:\n",
        "   ```python\n",
        "   print(f\"\\n{'='*60}\")\n",
        "   print(\"ğŸ“‹ ì¼ê´„ ë¶„ë¥˜ ê²°ê³¼ ìš”ì•½\")\n",
        "   print(f\"{'='*60}\")\n",
        "   for filename, pred_class, confidence in results_list:\n",
        "       print(f\"ğŸ“· {filename:25} â†’ {pred_class:20} ({confidence:.1f}%)\")\n",
        "   ```\n",
        "   - comprehensive summary(ì¢…í•© ìš”ì•½) ì¶œë ¥\n",
        "   - formatted table(ì„œì‹í™”ëœ í‘œ): filename(íŒŒì¼ëª…), prediction(ì˜ˆì¸¡), confidence(ì‹ ë¢°ë„)\n",
        "   - string formatting(ë¬¸ìì—´ ì„œì‹): ì •ë ¬ëœ column layout(ì—´ ë ˆì´ì•„ì›ƒ)\n",
        "\n",
        "9. **Successful completion(ì„±ê³µì  ì™„ë£Œ)**:\n",
        "   ```python\n",
        "   return results_list\n",
        "   ```\n",
        "   - all results(ëª¨ë“  ê²°ê³¼) ë°˜í™˜\n",
        "   - tuple list format(íŠœí”Œ ë¦¬ìŠ¤íŠ¸ í˜•ì‹): `(filename, class_name, confidence)`\n",
        "\n",
        "10. **Exception handling(ì˜ˆì™¸ ì²˜ë¦¬)**:\n",
        "    ```python\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        return None\n",
        "    ```\n",
        "    - generic error handling(ì¼ë°˜ ì˜¤ë¥˜ ì²˜ë¦¬)\n",
        "    - error message(ì˜¤ë¥˜ ë©”ì‹œì§€) ì¶œë ¥ í›„ `None` ë°˜í™˜\n",
        "\n",
        "**Function workflow(í•¨ìˆ˜ ì›Œí¬í”Œë¡œìš°):**\n",
        "1. User interface(ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤) ì´ˆê¸°í™”\n",
        "2. Multiple file upload(ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ) ì‹¤í–‰\n",
        "3. Upload validation(ì—…ë¡œë“œ ê²€ì¦)\n",
        "4. Classifier initialization(ë¶„ë¥˜ê¸° ì´ˆê¸°í™”)\n",
        "5. File iteration(íŒŒì¼ ë°˜ë³µ) ì²˜ë¦¬:\n",
        "   - Individual prediction(ê°œë³„ ì˜ˆì¸¡)\n",
        "   - Immediate result display(ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ)\n",
        "   - Result storage(ê²°ê³¼ ì €ì¥)\n",
        "6. Summary report(ìš”ì•½ ë³´ê³ ì„œ) ìƒì„±\n",
        "7. Final results(ìµœì¢… ê²°ê³¼) ë°˜í™˜\n",
        "\n",
        "**Key features(ì£¼ìš” íŠ¹ì§•):**\n",
        "- **Batch processing(ì¼ê´„ ì²˜ë¦¬)**: ì—¬ëŸ¬ images(ì´ë¯¸ì§€) ë™ì‹œ ì²˜ë¦¬\n",
        "- **Real-time feedback(ì‹¤ì‹œê°„ í”¼ë“œë°±)**: ê° image(ì´ë¯¸ì§€) ì²˜ë¦¬ ì¤‘ progress(ì§„í–‰ ìƒí™©) í‘œì‹œ\n",
        "- **Comprehensive summary(ì¢…í•© ìš”ì•½)**: ëª¨ë“  ê²°ê³¼ë¥¼ ì •ë¦¬ëœ format(í˜•ì‹)ìœ¼ë¡œ í‘œì‹œ\n",
        "- **Efficient workflow(íš¨ìœ¨ì  ì›Œí¬í”Œë¡œìš°)**: single classifier instance(ë‹¨ì¼ ë¶„ë¥˜ê¸° ì¸ìŠ¤í„´ìŠ¤) ì¬ì‚¬ìš©\n",
        "\n",
        "**Data structure(ë°ì´í„° êµ¬ì¡°):**\n",
        "- `results_list`: list of tuples(íŠœí”Œ ë¦¬ìŠ¤íŠ¸)\n",
        "- ê° tuple(íŠœí”Œ): `(filename, predicted_class, confidence_percentage)`\n",
        "\n",
        "**Use cases(ì‚¬ìš© ì‚¬ë¡€):**\n",
        "- Multiple image classification(ë‹¤ì¤‘ ì´ë¯¸ì§€ ë¶„ë¥˜)\n",
        "- Dataset evaluation(ë°ì´í„°ì…‹ í‰ê°€)\n",
        "- Bulk image analysis(ëŒ€ëŸ‰ ì´ë¯¸ì§€ ë¶„ì„)\n",
        "\n",
        "**Return value(ë°˜í™˜ê°’):**\n",
        "- Success case(ì„±ê³µ ì‹œ): list of tuples(íŠœí”Œ ë¦¬ìŠ¤íŠ¸) with classification results(ë¶„ë¥˜ ê²°ê³¼)\n",
        "- Failure case(ì‹¤íŒ¨ ì‹œ): `None`"
      ],
      "metadata": {
        "id": "wmwzBH5dxlPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„\n",
        "# ============================================================================="
      ],
      "metadata": {
        "id": "hf_hP5aUn7xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ¯ ImageNet 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜ê¸° ì‹¤í–‰ ì˜µì…˜:\")\n",
        "print(\"1. ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ë¥˜: classify_uploaded_image()\")\n",
        "print(\"2. ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ: compare_multiple_models()\")\n",
        "print(\"3. ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ë¶„ë¥˜: batch_classify()\")\n",
        "print(\"\\nğŸ’¡ ì¶”ì²œ: classify_uploaded_image() ë¡œ ì‹œì‘í•˜ì„¸ìš”!\")\n",
        "print(\"\\nğŸ§  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: ResNet50, VGG16, EfficientNet, MobileNet ë“±\")\n",
        "print(\"ğŸ“Š ë¶„ë¥˜ ê°€ëŠ¥: ë™ë¬¼, ì°¨ëŸ‰, ìŒì‹, ë„êµ¬, ìì—°ë¬¼ ë“± 1000ê°œ ì¹´í…Œê³ ë¦¬\")\n",
        "print(\"\\nâš¡ ì¤€ë¹„ ì™„ë£Œ! ì—…ë¡œë“œ ì „ìš© ImageNet ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤!\")\n",
        "\n",
        "# ì‚¬ìš©ìê°€ ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ\n",
        "classify_uploaded_image()"
      ],
      "metadata": {
        "id": "2iw-yn_Fn7rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYjROtmrn7fp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}