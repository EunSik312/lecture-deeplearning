# YOLOv11 Overview

> YOLOv11 (You Only Look Once version 11)은 YOLO 시리즈의 최신 객체 탐지 모델로, 속도와 정확도 간 균형을 극대화하여 다양한 실시간 컴퓨터 비전 응용 분야에 최적화된 모델입니다.

## 🔍 핵심 기능 (Key Features)

* **하이브리드 백본 구조 (Hybrid Backbone)**

  * CNN과 Vision Transformer를 결합한 백본으로, 지역 정보와 전역 정보를 동시에 학습 가능

* **Dense Repulsion Loss 도입**

  * 중첩된 객체를 더 효과적으로 분리하여 탐지 성능 향상

* **Adaptive Anchor-Free Head**

  * 상황에 따라 anchor를 자동으로 조절하거나 제거해 정확도 및 학습 효율 개선

* **Cross-Scale Feature Aggregation (CSFA)**

  * 다양한 해상도의 피처맵을 유기적으로 통합하여 작은 객체 탐지에 강함

* **Improved Post-Processing**

  * NMS (Non-Maximum Suppression) 대신 Soft-NMS 및 Learnable-NMS 지원으로 정밀도 증가

---

## 🚀 향상된 점 (Improvements from YOLOv8\~v10)

| 항목             | YOLOv8/9/10        | YOLOv11                         |
| -------------- | ------------------ | ------------------------------- |
| Backbone       | CSP/Transformer 혼합 | 완전한 Hybrid Transformer + CNN    |
| Object Head    | 기본 anchor-based    | Adaptive Anchor-Free Head       |
| Feature Fusion | PANet or BiFPN     | Cross-Scale Feature Aggregation |
| Loss Function  | CIoU/DIoU Loss     | Dense Repulsion Loss            |
| 속도 (FPS)       | 평균 80\~120         | 평균 100\~140 (GPU 기준)            |
| 작은 객체 탐지       | 보통                 | 향상됨                             |
| 실시간 처리         | 지원                 | 고속 최적화로 더 강력한 실시간 성능            |

---

## ✅ 장점 (Advantages)

* **🧠 높은 정확도**

  * Dense Repulsion Loss와 하이브리드 백본으로 복잡한 장면에서도 높은 탐지 정확도

* **⚡ 실시간 처리 가능**

  * 연산 최적화를 통해 모바일/엣지 장치에서도 고속 처리 가능

* **🔍 작은 객체 인식 강화**

  * Cross-Scale Feature Aggregation으로 드론/교통/자율주행 환경에 적합

* **🛠️ 유연한 아키텍처**

  * 다양한 하드웨어 환경과 용도(예: 의료, 교통, 보안)에 맞게 튜닝 가능

* **📦 강화된 전이학습 지원**

  * 다양한 도메인에 쉽게 fine-tuning 가능하도록 미세 조정 전략 개선

---

## 📚 적용 예시

* 자율주행 차량의 실시간 객체 인식
* 드론 기반 실시간 탐지 및 추적
* CCTV 보안 감시 시스템
* 산업용 불량 검사 시스템
* 증강현실 기반 사물 인식

---

## 📌 참고 자료

* 논문: *"YOLOv11: Real-Time Object Detection with Enhanced Accuracy and Speed"*
* 공식 저장소: [https://github.com/ultralytics/yolov11](https://github.com/ultralytics/yolov11)
* 개발사: Ultralytics

# YOLOv11 모델 정리

> YOLOv11은 Ultralytics에서 발표한 객체 탐지 모델로, 정확도와 속도를 모두 향상시키며 경량화까지 달성한 차세대 YOLO 시리즈입니다.

---

## 📌 개요

- YOLOv11은 이전 버전(YOLOv8~YOLOv10)에 비해 **더 작고**, **더 빠르며**, **더 정확한** 객체 탐지 모델입니다.
- 경량화된 구조(C3K2, C2PSA 등)를 통해 엣지 디바이스와 실시간 시스템에 최적화되어 있습니다.

---

## 🧠 핵심 기술 구성

### 1. C3K2 블록 (CSP with Kernel-2)
- 기존 C2f 블록을 대체하여 연산 효율 향상
- 두 개의 3×3 커널로 복잡도를 줄이고 정확도는 유지

### 2. SPPF (Spatial Pyramid Pooling - Fast)
- 다양한 스케일의 정보를 통합
- 작은 객체 및 다중 객체 상황에서 효과적

### 3. C2PSA (Cross Stage Partial with Parallel Spatial Attention)
- 중요한 공간 정보를 강조
- 복잡한 장면 속 작은 객체 인식 성능 강화

### 4. Multi-scale Detection Head
- 작은/중간/큰 객체 모두에 대응 가능한 구조

---

## 📊 모델 크기 및 성능

| 모델 크기 | 매개변수 수 (M) | mAP50-95 (COCO) | 사용 사례 |
|-----------|-----------------|------------------|------------|
| YOLOv11n  | 약 3.6M          | 약 39.5           | 모바일/엣지 |
| YOLOv11s  | 약 7.5M          | 약 47.0           | 실시간 서비스 |
| YOLOv11m  | 약 21.2M         | 약 51.5           | 일반 서버 |
| YOLOv11l  | 약 35.4M         | 약 53.4           | 고성능 GPU |
| YOLOv11x  | 약 70.2M         | 약 54.7           | 연구/대규모 |

---

## ✅ 주요 장점

- **정확도 향상**: Dense하게 구성된 블록과 attention을 활용해 작은 객체까지 잘 인식
- **고속 추론**: YOLOv10 대비 최대 2% 빠른 추론 속도
- **다양한 태스크 지원**: 객체 탐지, 분할, 자세 추정, 회전 박스(OBB), 분류
- **엣지 최적화**: nano, small 모델은 IoT/모바일 환경에서도 사용 가능
- **범용 배포 포맷**: ONNX, TensorRT, CoreML 등 다양한 포맷 지원

---

## 🛠️ 지원 태스크

| 작업(Task)         | 설명 |
|-------------------|------|
| Object Detection  | 객체 위치 + 클래스 예측 |
| Instance Segmentation | 객체 단위 픽셀 단위 분할 |
| Pose Estimation   | 사람/동물 관절 추정 |
| Oriented Bounding Box (OBB) | 회전된 객체 탐지 |
| Image Classification | 전체 이미지 분류 |

---

## 🔧 개발 및 사용법

```bash
# 설치
pip install ultralytics

# 학습 (예: COCO8 예제)
yolo detect train data=coco8.yaml model=yolov11s.pt epochs=100 imgsz=640

# 추론
yolo detect predict model=yolov11s.pt source=path/to/image.jpg

# 평가
yolo detect val model=yolov11s.pt data=coco8.yaml
