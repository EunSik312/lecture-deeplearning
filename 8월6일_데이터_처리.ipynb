{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgNiqJ4FZh4niWS2huAvx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EunSik312/lecture-deeplearning/blob/main/8%EC%9B%946%EC%9D%BC_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2Z5SCQc2zUEF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 1: 재귀적 DFS vs. 반복적 BFS\n",
        "\n",
        "**목표:**\n",
        "1.  깊이 우선 탐색(DFS)을 **재귀(Recursion)**를 사용하여 구현합니다.\n",
        "2.  너비 우선 탐색(BFS)을 **반복문과 큐(Queue)**를 사용하여 구현합니다.\n",
        "3.  두 알고리즘의 탐색 패턴을 시각화하여 프로그래밍 패러다임과 데이터 구조의 차이가 어떤 결과를 낳는지 직접 확인합니다.\n",
        "\n",
        "**핵심 개념:** 재귀(콜 스택)와 반복(명시적 큐)은 문제를 해결하는 두 가지 다른 접근 방식이며, 이는 알고리즘의 근본적인 동작을 결정합니다."
      ],
      "metadata": {
        "id": "IvIRzZmlzYgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%title: 필요한 라이브러리 임포트 및 그리드 설정\n",
        "!pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 그리드 설정 (0: 길, 1: 벽)\n",
        "grid = [\n",
        "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
        "    [0, 1, 1, 0, 1, 0, 1, 0, 1, 0],\n",
        "    [0, 1, 0, 0, 0, 0, 1, 0, 1, 0],\n",
        "    [0, 0, 0, 1, 1, 0, 1, 0, 0, 0],\n",
        "    [0, 1, 0, 0, 0, 0, 1, 1, 1, 0],\n",
        "    [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
        "    [0, 0, 0, 0, 1, 0, 1, 0, 1, 0],\n",
        "    [1, 1, 1, 0, 1, 0, 1, 0, 1, 0],\n",
        "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
        "    [0, 0, 1, 0, 1, 0, 0, 0, 1, 0]\n",
        "]\n",
        "\n",
        "start = (0, 0)\n",
        "goal = (9, 9)\n",
        "\n",
        "# 시각화 헬퍼 함수 (이전과 동일)\n",
        "def visualize_search(grid, visited_nodes, title):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(grid, cmap='Greys', interpolation='none')\n",
        "    plt.plot(start[1], start[0], 'bs', markersize=12, label='Start')\n",
        "    plt.plot(goal[1], goal[0], 'g*', markersize=16, label='Goal')\n",
        "    if visited_nodes:\n",
        "        for i, node in enumerate(visited_nodes):\n",
        "            plt.plot(node[1], node[0], 'r.', markersize=6, alpha=(i+1)/len(visited_nodes))\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.legend()\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY49-DglzW81",
        "outputId": "2d7154e0-62dc-4452-96e0-e5a24ecab363"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 과제 1: 재귀를 이용한 깊이 우선 탐색 (DFS)\n",
        "`dfs_recursive` 함수를 완성하세요. 이 함수는 자기 자신을 호출하여 이웃 노드를 탐색해야 합니다.\n",
        "- **Base Case (종료 조건):** 현재 노드가 목표이거나, 벽이거나, 이미 방문한 곳이면 탐색을 중단해야 합니다.\n",
        "- **Recursive Step (재귀 단계):** 유효한 이웃 노드에 대해 `dfs_recursive` 함수를 다시 호출합니다."
      ],
      "metadata": {
        "id": "TOwTUDew04US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title: 재귀적 DFS 구현\n",
        "\n",
        "def dfs_recursive_helper(grid, current, goal, visited, path_order):\n",
        "    rows, cols = len(grid), len(grid[0])\n",
        "    row, col = current\n",
        "\n",
        "    # 종료 조건 1: 그리드 밖이거나 벽인 경우\n",
        "\n",
        "    # 종료 조건 2: 이미 방문한 경우\n",
        "\n",
        "    # 현재 노드 방문 처리\n",
        "\n",
        "    # 종료 조건 3: 목표 도달\n",
        "\n",
        "    # 재귀 단계: 4방향 이웃에 대해 재귀 호출\n",
        "\n",
        "# DFS 실행을 위한 래퍼 함수\n",
        "def run_dfs(grid, start, goal):\n",
        "    visited = set()\n",
        "    path_order = []\n",
        "    dfs_recursive_helper(grid, start, goal, visited, path_order)\n",
        "    return path_order\n",
        "\n",
        "# 실행 및 시각화\n",
        "dfs_path = run_dfs(grid, start, goal)\n",
        "print(f\"DFS가 탐색한 노드 개수: {len(dfs_path)}\")\n",
        "visualize_search(grid, dfs_path, \"Recursive DFS Exploration Pattern\")"
      ],
      "metadata": {
        "id": "h_zTdJSr05ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 과제 2: 반복문과 큐를 이용한 너비 우선 탐색 (BFS)\n",
        "bfs_iterative 함수를 완성하세요. while 반복문과 큐(Python 리스트의 pop(0) 사용)를 이용하여 구현합니다."
      ],
      "metadata": {
        "id": "aJpQFXK50-d-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 반복적 BFS 구현\n",
        "\n",
        "def bfs_iterative(grid, start, goal):\n",
        "    rows, cols = len(grid), len(grid[0])\n",
        "\n",
        "    # 큐(Queue)로 사용할 리스트\n",
        "\n",
        "    # 방문한 노드를 기록\n",
        "\n",
        "    # 탐색 순서 기록\n",
        "\n",
        "    while queue:\n",
        "        # 큐의 맨 앞에서 노드를 꺼냄 (FIFO)\n",
        "\n",
        "        # 4방향 이웃 노드 탐색\n",
        "\n",
        "            # 유효성 검사\n",
        "\n",
        "    return path_order\n",
        "\n",
        "# 실행 및 시각화\n",
        "bfs_path = bfs_iterative(grid, start, goal)\n",
        "print(f\"BFS가 탐색한 노드 개수: {len(bfs_path)}\")\n",
        "visualize_search(grid, bfs_path, \"Iterative BFS Exploration Pattern\")"
      ],
      "metadata": {
        "id": "VnpraHyL0-1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 2: 벨만-포드 알고리즘과 동적 프로그래밍\n",
        "\n",
        "**목표:**\n",
        "1.  동적 프로그래밍의 바텀업(Bottom-up) 접근법인 벨만-포드 알고리즘을 구현합니다.\n",
        "2.  '반복적 완화(Iterative Relaxation)' 과정을 통해, 지역적 정보만으로 어떻게 전역 최적 해가 계산되는지 확인합니다.\n",
        "\n",
        "**핵심 개념:** 이 실습은 강의에서 배운 벨만 방정식의 재귀적 관계를 반복문을 통해 푸는 과정입니다. 각 반복은 경로의 길이를 하나씩 늘려가며 최적 비용을 찾아가는 동적 프로그래밍 테이블을 채우는 것과 같습니다."
      ],
      "metadata": {
        "id": "JvzA0O391Cj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 정의\n",
        "\n",
        "# 인터넷 라우터 네트워크를 시뮬레이션한다고 가정합니다.\n",
        "# 각 엣지는 (출발 노드, 도착 노드, 비용) 형태의 튜플입니다.\n",
        "num_vertices = 5\n",
        "edges = [\n",
        "    (0, 1, -1),\n",
        "    (0, 2, 4),\n",
        "    (1, 2, 3),\n",
        "    (1, 3, 2),\n",
        "    (1, 4, 2),\n",
        "    (3, 2, 5),\n",
        "    (3, 1, 1),\n",
        "    (4, 3, -3)\n",
        "]\n",
        "source_node = 0"
      ],
      "metadata": {
        "id": "maZmvO_J1InO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 벨만-포드 알고리즘 구현\n",
        "알고리즘의 핵심은 두 개의 중첩된 `for` 반복문입니다.\n",
        "1. 바깥 루프는 `V-1` 번 반복하여 정보가 네트워크 전체에 전파될 시간을 보장합니다.\n",
        "2. 안쪽 루프는 모든 엣지를 순회하며 '완화(relaxation)' 조건을 확인하고, 더 저렴한 경로를 발견하면 비용을 갱신합니다."
      ],
      "metadata": {
        "id": "f0gblgy61JXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 벨만-포드 함수 구현 및 실행\n",
        "\n",
        "def bellman_ford(edges, num_v, source):\n",
        "    # 1. 거리 초기화\n",
        "\n",
        "    # 2. V-1 번 반복하며 엣지 완화\n",
        "    for i in range(num_v - 1):\n",
        "        print(f\"--- 반복 {i+1} ---\")\n",
        "        # [문제] 모든 엣지에 대해 반복\n",
        "        for u, v, w in edges:\n",
        "            # 문제] 만약 노드 u까지의 현재 거리가 무한대가 아니고, 노드 u까지의 거리에 u에서 v로 가는 엣지의 가중치 w를 더한 값이 노드 v까지의 현재 거리보다 작다면\n",
        "                print(f\"  (엣지 {u}->{v}) 노드 {v}의 거리 갱신: {distances[v]:.2f} -> {distances[u] + w:.2f}\")\n",
        "                # 문제]  노드 v까지의 최단 거리를 이 새로운, 더 짧은 거리로 업데이트하라\n",
        "        print(f\"  현재 거리: {[f'{d:.2f}' for d in distances]}\")\n",
        "\n",
        "    return distances\n",
        "\n",
        "# 벨만-포드 알고리즘 실행\n",
        "shortest_distances = bellman_ford(edges, num_vertices, source_node)\n",
        "\n",
        "print(\"\\n--- 최종 결과 ---\")\n",
        "for i, dist in enumerate(shortest_distances):\n",
        "    print(f\"시작 노드 {source_node}에서 노드 {i}까지의 최단 거리: {dist}\")"
      ],
      "metadata": {
        "id": "iYyf7gyH1LzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 3: 학습된 정책(Policy) 실행하기\n",
        "\n",
        "**목표:**\n",
        "1.  강화학습의 최종 결과물인 '정책'이 무엇인지 이해합니다.\n",
        "2.  에이전트가 이 정책을 어떻게 사용하여 목표까지 이동하는지 시뮬레이션합니다.\n",
        "\n",
        "**핵심 개념:** 강의에서 배운 Q-러닝과 같은 복잡한 학습 과정의 결과는, 결국 '각 상태(위치)에서 어떤 행동을 해야 하는가'를 알려주는 이 간단한 화살표 지도(규칙)로 귀결됩니다. 우리는 이 '뇌'를 직접 실행해봅니다."
      ],
      "metadata": {
        "id": "IkbQDGt81PGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 정책과 환경 설정\n",
        "\n",
        "# 강화학습을 통해 이미 학습이 완료된 최적 정책이라고 가정합니다.\n",
        "policy_grid = [\n",
        "    ['>', '>', '>', 'v', '#'],\n",
        "    ['^', '#', '>', 'v', '#'],\n",
        "    ['^', '#', '>', 'v', 'G'],\n",
        "    ['^', '<', '<', '<', '<'],\n",
        "]\n",
        "\n",
        "start_pos = (3, 0)\n"
      ],
      "metadata": {
        "id": "QWenGSl71Pd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 정책 실행 시뮬레이터 구현\n",
        "간단한 `while` 반복문을 사용하여, 에이전트가 현재 위치의 정책을 읽고 다음 위치로 이동하는 과정을 목표에 도달할 때까지 반복합니다."
      ],
      "metadata": {
        "id": "T7jNoqCA1Pz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정책 실행 시뮬레이터 구현 및 실행\n",
        "\n",
        "def execute_policy(policy, start):\n",
        "    row, col = start\n",
        "    path = [(row, col)]\n",
        "\n",
        "    # 최대 20번만 이동하도록 제한 (무한 루프 방지)\n",
        "    for _ in range(20):\n",
        "        # [문제] 현재 에이전트가 있는 위치의 정책(가야 할 방향)을 확인합니다.\n",
        "\n",
        "        # [문제] 만약 현재 위치가 'G' (목표 지점)이면\n",
        "            # [문제] \"목표 도달!\" 이라고 출력하고\n",
        "            # [문제] 지금까지 지나온 길(경로)을 반환하고 함수를 끝냅니다.\n",
        "\n",
        "        # [문제] 만약 정책이 '>' (오른쪽)이면, 오른쪽으로 한 칸 이동합니다.\n",
        "        # [문제] 아니면 만약 정책이 '<' (왼쪽)이면, 왼쪽으로 한 칸 이동합니다.\n",
        "        # [문제] 아니면 만약 정책이 'v' (아래쪽)이면, 아래쪽으로 한 칸 이동합니다.\n",
        "        # [문제] 그 외에 만약 정책이 '^' (위쪽)이면, # 위쪽으로 한 칸 이동합니다.\n",
        "\n",
        "        path.append((row, col))\n",
        "\n",
        "    print(\"경로를 찾지 못했거나 너무 오래 걸렸습니다.\")\n",
        "    return path\n",
        "\n",
        "# 정책 실행\n",
        "agent_path = execute_policy(policy_grid, start_pos)\n",
        "\n",
        "print(\"\\n--- 에이전트의 이동 경로 ---\")\n",
        "print(\" -> \".join(map(str, agent_path)))\n",
        "\n",
        "# (선택) 경로를 간단하게 시각화\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "grid_for_viz = np.zeros((len(policy_grid), len(policy_grid[0])))\n",
        "goal_pos = None\n",
        "for r in range(len(policy_grid)):\n",
        "    for c in range(len(policy_grid[0])):\n",
        "        if policy_grid[r][c] == '#': grid_for_viz[r, c] = 0.5\n",
        "        if policy_grid[r][c] == 'G': goal_pos = (r, c)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.imshow(grid_for_viz, cmap='viridis', alpha=0.6)\n",
        "path_rows = [p[0] for p in agent_path]\n",
        "path_cols = [p[1] for p in agent_path]\n",
        "plt.plot(path_cols, path_rows, 'r-o', label='Agent Path')\n",
        "plt.plot(start_pos[1], start_pos[0], 'bs', markersize=10, label='Start')\n",
        "if goal_pos:\n",
        "    plt.plot(goal_pos[1], goal_pos[0], 'g*', markersize=15, label='Goal')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HsoopJNk1QMl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}