## 📊 mAP 그래프란

### ✅ 정의

\*\*mAP(mean Average Precision)\*\*는 객체 탐지에서 **예측이 얼마나 정확한지**를 수치로 나타낸다.

* **AP (Average Precision)**: 한 클래스에 대해 precision-recall 곡선의 면적
* **mAP**: 모든 클래스의 AP 평균값

> 예: 3개의 클래스가 있다면
> `mAP = (AP_class1 + AP_class2 + AP_class3) / 3`

---

## 📈 mAP 관련 그래프 종류

| 그래프                         | 설명                                               |
| --------------------------- | ------------------------------------------------ |
| **Precision-Recall Curve**  | 다양한 confidence threshold에서 precision과 recall의 관계 |
| **mAP vs Epoch**            | 훈련 중 mAP 성능이 어떻게 변화하는지 시각화                       |
| **Class-wise AP bar chart** | 각 클래스별 Average Precision 표시                      |
| **IoU vs mAP**              | IoU(교차/합 비율)가 높아질수록 mAP이 어떻게 변하는지 보여줌            |

---

### 🔍 예시: PR Curve (Precision-Recall)

![예시: PR 곡선](https://raw.githubusercontent.com/ultralytics/yolov5/master/docs/images/pr_curve.png)

* 빨간색: precision ↑
* 파란색: recall ↑
  곡선 아래 면적이 클수록 AP가 높고, 결국 mAP도 높음.

---

## 🧪 YOLO 훈련 시 mAP 그래프 확인 방법

Ultralytics YOLO (`v8~v12`)로 모델 훈련 시, 자동으로 성능 그래프됨.

```bash
runs/detect/train/  # 내부에 다음과 같은 그래프 있음:
├── results.png       # Loss, mAP, Precision 등 종합 그래프
├── PR_curve.png      # PR 커브
├── F1_curve.png      # F1-score 곡선
├── confusion_matrix.png  # 혼동 행렬
```

또는 코드에서 직접 확인:

```python
from IPython.display import Image
Image(filename='runs/detect/train/results.png')
```

---

## ✅ 요약

| 항목             | 설명                                |
| -------------- | --------------------------------- |
| **mAP**        | 객체 탐지 정확도의 대표적인 성능 지표             |
| **mAP 그래프 종류** | PR 곡선, epoch 변화 그래프, 클래스별 막대그래프 등 |
| **높을수록 좋은 값**  | 보통 0.5 이상이면 양호, 0.7 이상이면 매우 우수    |
| **자동 생성 위치**   | `runs/detect/train/` 폴더 내 그래프 파일들 |

---
